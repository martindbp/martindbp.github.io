<!DOCTYPE html>
<html prefix="" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is the personal blog of Martin Pettersson">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>martindbp | martindbp</title>
<link href="../assets/css/all.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">
<link rel="canonical" href="https://martindbp.com/posts/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script><!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]-->
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
            styles, `#sidebar-checkbox` for behavior. -->
    <input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox"><!-- Toggleable sidebar --><div class="sidebar" id="sidebar">

        <nav role="navigation" class="sidebar-nav"><!--<a class="sidebar-nav-item" href="/"><i class="fa fa-2x fa-fw fa-home" /> Home</a>--><!--<a class="sidebar-nav-item" href="/about"><i class="fa fa-2x fa-fw fa-user-circle" /> About</a>--></nav><nav id="menu" role="navigation" class="sidebar-nav"><a class="sidebar-nav-item" href="../index.html">Home</a>
        <a class="sidebar-nav-item" href="../archive.html">Archives</a>
        <a class="sidebar-nav-item" href="../categories/index.html">Tags</a>
        <a class="sidebar-nav-item" href="../rss.xml">RSS feed</a>
    
    
    </nav>
</div>

    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          
    <h2 id="brand" class="masthead-title">
      <a href="https://martindbp.com/" title="martindbp" rel="home">martindbp</a>
    </h2>

        </div>
      </div>

      <div class="container content" id="content">
        

<div class="posts">
    <article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="name-statistics/" class="u-url">Are parents picking less common names?</a></h1>
        <div class="metadata">
            <p class="dateline"><a href="name-statistics/" rel="bookmark"><time class="post-date published dt-published" datetime="2019-10-23T22:03:02+10:00" title="2019-10-23 22:03">2019-10-23 22:03</time></a></p>
                <p class="commentline">
        
    <a href="name-statistics/#disqus_thread" data-disqus-identifier="cache/posts/name_statistics.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I think we all have the gut feeling that parents nowadays try to pick more unique names, or at least not names that are <em>too</em> common. Instead of relying on a gut feeling or anectdata, let's check!</p>
<p>Being Swedish, of course I'm mostly interested in Swedish name statistics, and luckily SCB (the central statistics bureau) provides an Excel spread sheet with the frequency statistics of the top 100 names for boys and girls from 1998 to 2017. Let's download it:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span> wget -O stats.xlsx https://www.scb.se/hitta-statistik/statistik-efter-amne/befolkning/amnesovergripande-statistik/namnstatistik/pong/tabell-och-diagram/nyfodda--efter-namngivningsar-och-tilltalsnamn-topp-100/Namn-1998-/
</pre></div>

    </div>
</div>
</div>

        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
</div>
</div>

        
    
  
  
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can read the spreadsheet with Python and pandas/numpy (I bet it would be easier to just do this in Excel, but I'm not an Excel-ninja...) and collect the statistics.</p>
<p>Let's load the Excel file and look at the data:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (27 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">START_YEAR</span><span class="p">,</span> <span class="n">END_YEAR</span> <span class="o">=</span> <span class="mi">1998</span><span class="p">,</span> <span class="mi">2017</span>
<span class="n">GENDERS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'girls'</span><span class="p">,</span> <span class="s1">'boys'</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'year'</span><span class="p">,</span> <span class="s1">'name'</span><span class="p">,</span> <span class="s1">'gender'</span><span class="p">,</span> <span class="s1">'count'</span><span class="p">,</span> <span class="s1">'percent'</span><span class="p">])</span>

<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'stats.xlsx'</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">START_YEAR</span><span class="p">,</span> <span class="n">END_YEAR</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">gender_idx</span><span class="p">,</span> <span class="n">gender</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">GENDERS</span><span class="p">):</span>
        <span class="n">sheet_idx</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">year</span> <span class="o">-</span> <span class="n">START_YEAR</span><span class="p">)</span> <span class="o">+</span> <span class="n">gender_idx</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="n">sheet_idx</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="s1">'B:D'</span><span class="p">)</span>
        <span class="n">count_col</span> <span class="o">=</span> <span class="s1">'Antal'</span> <span class="k">if</span> <span class="s1">'Antal'</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">else</span> <span class="s1">'Antal b√§rare'</span>        
        <span class="n">counts</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">count_col</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">name_col_idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">count_col</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">names</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="n">name_col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="c1"># NOTE: need to strip spaces</span>
        <span class="c1"># When there are ties in count, there will be more than 100 rows. Keep the top 100</span>
        <span class="n">counts</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> <span class="n">names</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
        <span class="n">years</span> <span class="o">=</span> <span class="p">[</span><span class="n">year</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
        <span class="n">genders</span> <span class="o">=</span> <span class="p">[</span><span class="n">gender</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">'year'</span><span class="p">:</span> <span class="n">years</span><span class="p">,</span> <span class="s1">'gender'</span><span class="p">:</span> <span class="n">genders</span><span class="p">,</span> <span class="s1">'name'</span><span class="p">:</span> <span class="n">names</span><span class="p">,</span> <span class="s1">'count'</span><span class="p">:</span> <span class="n">counts</span><span class="p">,</span> 
                               <span class="s1">'percent'</span><span class="p">:</span> <span class="n">counts</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span> <span class="o">/</span> <span class="n">counts</span><span class="o">.</span><span class="n">sum</span><span class="p">()}),</span>
            <span class="n">sort</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>    count gender    name   percent  year
1    1468  girls    Emma  0.043336  1998
2    1171  girls   Julia  0.034568  1998
3    1043  girls    Elin  0.030790  1998
4    1037  girls  Amanda  0.030613  1998
5    1006  girls   Hanna  0.029697  1998
..    ...    ...     ...       ...   ...
96    145   boys    Thor  0.004173  2017
97    142   boys  Milian  0.004087  2017
98    141   boys    Levi  0.004058  2017
99    141   boys    Vide  0.004058  2017
100   139   boys     Neo  0.004000  2017

[4000 rows x 5 columns]
</pre>
</div>
</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's plot what the top 100 names looked like in 1998 and 2017:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (11 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1998</span><span class="p">,</span> <span class="mi">2017</span><span class="p">]:</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">girls_year</span> <span class="o">=</span> <span class="n">data</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s1">'year'</span><span class="p">]</span> <span class="o">==</span> <span class="n">year</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">'gender'</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'girls'</span><span class="p">)]</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">'name'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">'percent'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">girls_year</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">get_xticklabels</span><span class="p">(),</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">));</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">f</span><span class="s1">'Girls </span><span class="si">{year}</span><span class="s1">'</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These distributions look quite different, but the question is what's a good measure for the unevenness of the name distribution so that we can compare different years. I'm sure there are many options for this, but I'll pick <em>perplexity</em> which is the exponentiated <em>entropy</em>. The entropy of the distribution measures the disorder, i.e. we get the highest entropy if all names have an equal probability, and low entropy if everyone named their child the same way. Perplexity can be seen as the average number of "choices" one has in the random variable, e.g. a 6-sided fair die has a perplexity of 6, while a cheating die that always ends up on one number has a perplexity of 1. This is a bit easier to interpret than entropy, which is the average number of bits needed to encode an event from that distribution.</p>
<p>Let's calculate the perplexity over the name distribution for each year and gender and plot it over time:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (14 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">perplexity_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'year'</span><span class="p">,</span> <span class="s1">'perplexity'</span><span class="p">,</span> <span class="s1">'gender'</span><span class="p">])</span>
<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">START_YEAR</span><span class="p">,</span> <span class="n">END_YEAR</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">gender</span> <span class="ow">in</span> <span class="n">GENDERS</span><span class="p">:</span>
        <span class="n">counts</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s1">'year'</span><span class="p">]</span> <span class="o">==</span> <span class="n">year</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">'gender'</span><span class="p">]</span> <span class="o">==</span> <span class="n">gender</span><span class="p">),</span> <span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">counts</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">probs</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">perplexity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">entropy</span><span class="p">)</span>
        <span class="n">perplexity_data</span> <span class="o">=</span> <span class="n">perplexity_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">{</span><span class="s1">'year'</span><span class="p">:</span> <span class="n">year</span><span class="p">,</span> <span class="s1">'perplexity'</span><span class="p">:</span> <span class="n">perplexity</span><span class="p">,</span> <span class="s1">'gender'</span><span class="p">:</span> <span class="n">gender</span><span class="p">},</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">START_YEAR</span><span class="p">,</span> <span class="n">END_YEAR</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">START_YEAR</span><span class="p">,</span> <span class="n">END_YEAR</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">'year'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">'perplexity'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">'gender'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">perplexity_data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It seems like within the top 100 names, the answer is an unequivocal yes! Parents are spreading out their name choices more and more, approaching 90/100 which is quite even.</p>

</div>
</div>
</div>
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another interesting thing to check is whether names comes into, and goes out of fashion quicker over the years. My intuition tells me that due to naming lists being published online etc, this might be the case. One way we could check is to measure some kind of difference between the name distributions between adjacent years. One measure we could use is the KL-divergence, which tells us in a sense how different one distribution is from another expected distribution:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (23 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">kl_divs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">year1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">START_YEAR</span><span class="p">,</span> <span class="n">END_YEAR</span><span class="p">):</span>
    <span class="n">year2</span> <span class="o">=</span> <span class="n">year1</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">data_year1</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">'year'</span><span class="p">]</span> <span class="o">==</span> <span class="n">year1</span><span class="p">]</span>
    <span class="n">data_year2</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">'year'</span><span class="p">]</span> <span class="o">==</span> <span class="n">year2</span><span class="p">]</span>
    <span class="n">names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">data_year1</span><span class="p">[</span><span class="s1">'name'</span><span class="p">])</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">data_year2</span><span class="p">[</span><span class="s1">'name'</span><span class="p">]))</span>
    <span class="n">name_stats_year1</span> <span class="o">=</span> <span class="n">data_year1</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data_year1</span><span class="p">[</span><span class="s1">'name'</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">names</span><span class="p">),</span> <span class="p">[</span><span class="s1">'name'</span><span class="p">,</span> <span class="s1">'count'</span><span class="p">]]</span>
    <span class="n">name_stats_year2</span> <span class="o">=</span> <span class="n">data_year2</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data_year2</span><span class="p">[</span><span class="s1">'name'</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">names</span><span class="p">),</span> <span class="p">[</span><span class="s1">'name'</span><span class="p">,</span> <span class="s1">'count'</span><span class="p">]]</span>
    <span class="n">name_stats_year1</span> <span class="o">=</span> <span class="n">name_stats_year1</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">'name'</span><span class="p">)</span>
    <span class="n">name_stats_year2</span> <span class="o">=</span> <span class="n">name_stats_year2</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">'name'</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">name_stats_year1</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">q</span> <span class="o">/</span> <span class="n">q</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">name_stats_year2</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">p</span> <span class="o">/</span> <span class="n">p</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">kl_div</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">p</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">q</span><span class="o">/</span><span class="n">p</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">kl_divs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kl_div</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">START_YEAR</span><span class="p">,</span> <span class="n">END_YEAR</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">START_YEAR</span><span class="p">,</span> <span class="n">END_YEAR</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">kl_div_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'year'</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">START_YEAR</span><span class="p">,</span> <span class="n">END_YEAR</span><span class="p">)),</span> <span class="s1">'KL divergence'</span><span class="p">:</span> <span class="n">kl_divs</span><span class="p">})</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">'year'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">'KL divergence'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">kl_div_data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Surprisingly, for me at least, it seems intra-year KL divergence has gone down, but come to think of it, it makes sense. In 1998 when the distribution was more uneven, naming trends (e.g. a popular name waning) would have a large impact on the naming distribution, while a more even distribution suggests smaller changes between years.</p>

</div>
</div>
</div>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="can-i-say-this/" class="u-url">"Can I Say This In Chinese" with BERT</a></h1>
        <div class="metadata">
            <p class="dateline"><a href="can-i-say-this/" rel="bookmark"><time class="post-date published dt-published" datetime="2019-10-09T21:09:01+10:00" title="2019-10-09 21:09">2019-10-09 21:09</time></a></p>
                <p class="commentline">
        
    <a href="can-i-say-this/#disqus_thread" data-disqus-identifier="cache/posts/can_i_say_this.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Introduction">Introduction<a class="anchor-link" href="can-i-say-this/#Introduction">¬∂</a>
</h3>
<p>As it turns out, most people are not very inclined to teaching. I'm learning Chinese, my wife <em>is</em> Chinese, seems like a match made in heaven. Except that she has no patience whatsoever with my broken Chinese (though she's wonderful in many other ways). Whenever I ask how to say something in Chinese, she anwers with either "I don't know" or "you can't say that (followed by no explanation)". The only way I can get anything out of her is by trying to say something in Chinese and asking whether it sounds right or not. This is less mentally taxing for her than actually having to translate from English, which I understand, especially for two languages so dissimilar.</p>
<p>Now I'm thinking, with the recent advances in Natural Language Processing with Deep Learning, maybe I can create something to replace my unwilling wife. The academic name for this task seems to be "Linguistic Acceptability". Exactly what this includes seems to be up for debate.  For example, "the mouse ate the cat" is perfectly grammatical, although highly unlikey. Then there are sentences which are grammatical but seem logically impossible, like "the cat is a bus". This sentence makes no sense <em>unless</em> you've watched the movie Totoro, which features a... cat that is also a bus. Since this seems like a very difficult problem, I'll be focusing more on distinguishing grammatical vs. ungrammatical rather than sensical vs. nonsensical.</p>
<h3 id="Defining-the-problem">Defining the problem<a class="anchor-link" href="can-i-say-this/#Defining-the-problem">¬∂</a>
</h3>
<p>Recent Deep Learning architectures like BERT and GPT-2 basically train a <em>language model</em> or LM, i.e. given the surrounding context, they try to predict the missing word. In GPT-2s case, it predicts the next word given all the <em>previous</em> words in the sentence, while BERT predicts a missing word (a cloze) given both the words before and after it (the B in BERT stands for bidirectional). As such, GPT-2 works better as a language model, defining the joint probability over a sequence of words, while BERT's masked LM is less straight forward to use as such. As a reminder, the joint probability can be refactored recursively using the chain rule:</p>
$$P(w_{1:n}) = P(w_n | w_{1:n-1})P(w_{1:n-1}) = P(w_n | w_{1:n-1}) \cdot \ldots \cdot P(w_2 | w_1)P(w_1)$$<p>Each of these factors is exactly what we get out of GPT-2, which means if we run inference and multiply the factors we get the joint probability, or actually more of an unormalized likelihood, of the whole sentence. BERT on the other hand gives us $P(w_k | w_{1:k-1}, w_{k+1:n})$ which is harder to intepret. There is research exploring ways of getting a joint probability model out of BERT <a href="https://www.aclweb.org/anthology/W19-2304">using MRFs (Markov Random Fields)</a>, but I'd like to keep things simple for this little project.</p>
<p>Using GPT-2 will be difficult, since training it from scratch, having 1.5 <em>billion</em> weights, requires a <a href="https://blog.usejournal.com/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc">cluster of GPUs and roughly $50k</a>. So I'm constrained to pre-trained versions, of which there is none for Chinese AFAIK. The Python library pytorch-transformers <em>does</em> however have a pre-trained BERT for Chinese.</p>
<h4 id="How-can-we-use-BERT?">How can we use BERT?<a class="anchor-link" href="can-i-say-this/#How-can-we-use-BERT?">¬∂</a>
</h4>
<p>Being constrained by time and money leaves me no option but to use BERT at this point. While BERT can't be used as a language model per-se, we can perhaps use the output in some useful way.</p>
<p>We'd like to get a binary decision whether a sentence is acceptable or not. We could try to use the masked probability for each word in the sentence, but again, it will be difficult to find some absolute thresold to distinguish unlikely sentences from unacceptable ones. What we could do is to train a classifier based on BERT with a dataset of positive and negative examples. While there are such datasets for other languages (CoLA - Corpus of Linguistic Acceptablility), I have not found such a dataset for Chinese.</p>
<p>I was however able to crawl some examples from the <a href="https://resources.allsetlearning.com/chinese/grammar/">AllSet grammar wiki</a> (licensed with CC-NC) with in total 436 and 461 negative and positive examples respectively, split into grammar groups based on page (note: this will take some time to run):</p>

</div>
</div>
</div>
  
  
  
  
  
    
      
        
        

        
          <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span> wget --quiet --mirror --convert-links --adjust-extension --follow-tags<span class="o">=</span>a --no-parent resources.allsetlearning.com/chinese/grammar/
<span class="o">!</span> grep -r -e <span class="s1">'class="x"'</span> resources.allsetlearning.com/chinese/**/* <span class="p">|</span><span class="err">\</span>
  <span class="n">sed</span> <span class="o">-</span><span class="n">e</span> <span class="s1">'s/&lt;li class="x"&gt;//g'</span> <span class="o">-</span><span class="n">e</span> <span class="s1">'s/&lt;span .*//g'</span> <span class="o">-</span><span class="n">e</span> <span class="s1">'s/&lt;\/*[a-z]*&gt;//g'</span> <span class="o">-</span><span class="n">e</span> <span class="s1">'s/ //g'</span> <span class="o">-</span><span class="n">e</span> <span class="s1">'s/:.*‚Üí/:/g'</span> \
  <span class="o">&gt;</span> <span class="s2">"$cache_path/allset_negative_examples.txt"</span>
<span class="o">!</span> grep -r -e <span class="s1">'class="o"'</span> resources.allsetlearning.com/chinese/**/* <span class="p">|</span><span class="err">\</span>
  <span class="n">sed</span> <span class="o">-</span><span class="n">e</span> <span class="s1">'s/&lt;li class="o"&gt;//g'</span> <span class="o">-</span><span class="n">e</span> <span class="s1">'s/&lt;span .*//g'</span> <span class="o">-</span><span class="n">e</span> <span class="s1">'s/&lt;\/*[a-z]*&gt;//g'</span> <span class="o">-</span><span class="n">e</span> <span class="s1">'s/ //g'</span> <span class="o">-</span><span class="n">e</span> <span class="s1">'s/:.*‚Üí/:/g'</span> \
  <span class="o">&gt;</span> <span class="s2">"$cache_path/allset_positive_examples.txt"</span>
</pre></div>

    </div>
</div>
</div>

        
    

    
      
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>While it's putting the car before the horse a bit, I suspected (correctly) that this small dataset would not be enough to train a classifier that generalizes well to any output. There are just too few examples to generalize to all the ways sentences can be correct and wrong, although these examples do contain many important and subtle errors learners commit.</p>

</div>
</div>
</div>
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Self-supervised-learning">Self-supervised learning<a class="anchor-link" href="can-i-say-this/#Self-supervised-learning">¬∂</a>
</h3>
<p>Instead of only training on the small dataset, the idea is to pre-train a classifier in a self-supervised way by generating negative examples from positive ones. While the masked probabilities of all the words in a sentence is not enough to tell the acceptability of the sentence, we can assume there is useful information in the <em>relative</em> scores, or losses, between sentences.</p>
<p>Using relative losses, we can generate negative samples from positive ones by finding a <em>mutation</em> that significantly increases the loss. Let's define the loss for a sentence as the average (since we're possibly comparing sentences of differing lengths) Cross-Entropy loss for each word: 
$$
L(S) = -\frac{1}{N}\sum_{i=1}^{N}{\log(P(w_i  | w_{1:i-1}, w_{i+1:N}))}
$$
Then we can perform take a correct sentence $S_c$ and perform a random mutation to get $S_m$. If $L(S_m) - L(S_c) &gt; \epsilon$ we consider it to be unacceptable.</p>
<p>Note that even if we could use the bidirectional probabilities/losses to directly do classification, this is something we'd like to avoid since calculating this loss requires a forward pass for <em>every</em> token in the sentence. Using these expensively generated examples to train a classifier let's us bypass this problem.</p>
<h4 id="Hard-Negatives">Hard Negatives<a class="anchor-link" href="can-i-say-this/#Hard-Negatives">¬∂</a>
</h4>
<p>This way we can generate unacceptable sentences from any acceptable one. Now since there are many possible ways to mutate a sentence that increases the loss more than $\epsilon$, we can pick the minimal one that passes this threshold. This is similar to <em>hard negative mining</em> where if you already have a model, you can improve it by sampling hard negatives and retraining the model. This is common in image classification and localization where any part of an image <em>not</em> containing the specified object are potential negative examples. Then it makes sense to pick the ones that are misclassified or get high losses from the initial model.</p>
<h4 id="Mutations">Mutations<a class="anchor-link" href="can-i-say-this/#Mutations">¬∂</a>
</h4>
<p>For the actual sentences, we could use the original corpus, but I prefer using sentences from <a href="can-i-say-this/tatoeba.org">Tatoeba</a> since it is a good source of informal language suitable for learners.</p>
<p>For mutating the sentences, there are a few things we can do:</p>
<ul>
<li>Permute the words</li>
<li>Swap two words</li>
<li>Insert word (sampled based on corpus frequency)</li>
<li>Replace word (sampled based on corpus frequency)</li>
<li>Delete word</li>
</ul>
<p>While we want to mutate the sentences to get unacceptable ones, there is some degree of unacceptability, and we want to generate ones that are <em>hard</em>, i.e. just barely unacceptable. Therefore I exclude random permutations since they are very unlikely to produce something close to acceptability.</p>
<p>Similarly for insertions and word replacements, it makes more sense to sample common words more frequently than rare words since the language has a very long tail of very infrequent words.</p>
<p>Below is the code for loading the Tatoeba dataset and generating hard negatives.
(NOTE: this is <em>a lot</em> of not very interesting code, but it is runnable if you run this in a Jupyter Notebook or Google Colab environment). Also worth mentioning is that the starting point for the PyTorch training was this <a href="https://mccormickml.com/2019/07/22/BERT-fine-tuning/">Colab Notebook</a>, which serves as a good tutorial for fine-tuning BERT for sequence classification.</p>
<p>First, installing some pip packages:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install --quiet pytorch-transformers pytorch-nlp hanziconv jieba sympy
</pre></div>

    </div>
</div>
</div>

        
    

    
      
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import a pre-trained Masked LM BERT model and define functions for preparing data for this model, as well as functions for predicting based on it, and calculating losses for whole sentences:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (224 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>
<span class="kn">from</span> <span class="nn">hanziconv</span> <span class="k">import</span> <span class="n">HanziConv</span>
<span class="kn">from</span> <span class="nn">sympy.ntheory</span> <span class="k">import</span> <span class="n">factorint</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">lru_cache</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="k">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span><span class="p">,</span> <span class="n">SequentialSampler</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.sequence</span> <span class="k">import</span> <span class="n">pad_sequences</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GroupKFold</span>
<span class="kn">from</span> <span class="nn">pytorch_transformers</span> <span class="k">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertConfig</span><span class="p">,</span> <span class="n">BertModel</span>
<span class="kn">from</span> <span class="nn">pytorch_transformers</span> <span class="k">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">BertForMaskedLM</span>
<span class="kn">from</span> <span class="nn">pynvml</span> <span class="k">import</span> <span class="n">nvmlInit</span><span class="p">,</span> <span class="n">nvmlDeviceGetHandleByIndex</span><span class="p">,</span> <span class="n">nvmlDeviceGetMemoryInfo</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">matthews_corrcoef</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">accuracy_score</span>

<span class="o">%</span> <span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">device_name</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()</span>
<span class="k">if</span> <span class="n">device_name</span> <span class="o">!=</span> <span class="s1">'/device:GPU:0'</span><span class="p">:</span>
  <span class="k">raise</span> <span class="ne">SystemError</span><span class="p">(</span><span class="s1">'GPU device not found'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Found GPU at: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">device_name</span><span class="p">))</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="n">n_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">gpu_usage</span><span class="p">(</span><span class="n">print_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">""" Convenience function to check GPU memory usage. Returns free memory in GB """</span>
  <span class="n">nvmlInit</span><span class="p">()</span>
  <span class="n">handle</span> <span class="o">=</span> <span class="n">nvmlDeviceGetHandleByIndex</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">info</span> <span class="o">=</span> <span class="n">nvmlDeviceGetMemoryInfo</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">print_stats</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Total memory: {info.total/1e9:.2f} GB"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Free memory: {info.free/1e9:.2f} GB"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Used memory: {info.used/1e9:.2f} GB"</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">info</span><span class="o">.</span><span class="n">free</span><span class="o">/</span><span class="mf">1e9</span>

<span class="c1"># Make sure we have enough memory</span>
<span class="k">if</span> <span class="n">gpu_usage</span><span class="p">(</span><span class="n">print_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">:</span>
  <span class="k">raise</span> <span class="ne">SystemError</span><span class="p">(</span><span class="s1">'Not enough memory'</span><span class="p">)</span>

<span class="c1"># Load pre-trained model tokenizer (vocabulary)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'bert-base-chinese'</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Load pre-trained model (weights)</span>
<span class="n">masked_lm_model</span> <span class="o">=</span> <span class="n">BertForMaskedLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'bert-base-chinese'</span><span class="p">)</span>
<span class="n">masked_lm_model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">add_cls_sep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="n">sentences</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sentence</span><span class="o">.</span><span class="n">values</span>
  <span class="c1"># We need to add special tokens at the beginning and end of each sentence for BERT to work properly</span>
  <span class="k">if</span> <span class="n">add_cls_sep</span><span class="p">:</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"[CLS] "</span> <span class="o">+</span> <span class="n">sentence</span> <span class="o">+</span> <span class="s2">" [SEP]"</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
  <span class="n">has_labels</span> <span class="o">=</span> <span class="s1">'label'</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span>
  <span class="k">if</span> <span class="n">has_labels</span><span class="p">:</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">values</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">))</span>

  <span class="n">tokenized_texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>

  <span class="c1"># Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. </span>
  <span class="c1"># In the original paper, the authors used a length of 512.</span>
  <span class="n">MAX_LEN</span> <span class="o">=</span> <span class="mi">128</span>

  <span class="c1"># Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary</span>
  <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tokenized_texts</span><span class="p">]</span>

  <span class="c1"># Pad our input tokens</span>
  <span class="n">input_ids</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">"long"</span><span class="p">,</span> <span class="n">truncating</span><span class="o">=</span><span class="s2">"post"</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"post"</span><span class="p">)</span>

  <span class="c1"># Create attention masks</span>
  <span class="n">attention_masks</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1"># Create a mask of 1s for each token followed by 0s for padding</span>
  <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">:</span>
    <span class="n">seq_mask</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">]</span>
    <span class="n">attention_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seq_mask</span><span class="p">)</span>

  <span class="c1"># Use train_test_split to split our data into train and validation sets for training</span>
  <span class="c1"># but if test_size is zero then only generate training sets</span>
  <span class="k">if</span> <span class="n">test_size</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
    <span class="n">train_inputs</span><span class="p">,</span> <span class="n">validation_inputs</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">validation_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2018</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>
    <span class="n">train_masks</span><span class="p">,</span> <span class="n">validation_masks</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">attention_masks</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2018</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">train_inputs</span> <span class="o">=</span> <span class="n">input_ids</span>
    <span class="n">train_labels</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="n">train_masks</span> <span class="o">=</span> <span class="n">attention_masks</span>
    <span class="n">validation_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">validation_labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">validation_masks</span> <span class="o">=</span> <span class="p">[]</span>
    
  <span class="c1"># Convert all of our data into torch tensors, the required datatype for our model</span>
  <span class="n">train_inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_inputs</span><span class="p">)</span>
  <span class="n">validation_inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">validation_inputs</span><span class="p">)</span>
  <span class="n">train_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
  <span class="n">validation_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">validation_labels</span><span class="p">)</span>
  <span class="n">train_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_masks</span><span class="p">)</span>
  <span class="n">validation_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">validation_masks</span><span class="p">)</span>

  <span class="c1"># Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, </span>
  <span class="c1"># with an iterator the entire dataset does not need to be loaded into memory</span>
  <span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">train_inputs</span><span class="p">,</span> <span class="n">train_masks</span><span class="p">,</span> <span class="o">*</span><span class="p">([</span><span class="n">train_labels</span><span class="p">]</span> <span class="k">if</span> <span class="n">has_labels</span> <span class="k">else</span> <span class="p">[]))</span>
  <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
    <span class="n">train_sampler</span> <span class="o">=</span> <span class="n">RandomSampler</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">train_sampler</span> <span class="o">=</span> <span class="n">SequentialSampler</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
  <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

  <span class="n">validation_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">validation_inputs</span><span class="p">,</span> <span class="n">validation_masks</span><span class="p">,</span> <span class="o">*</span><span class="p">([</span><span class="n">validation_labels</span><span class="p">]</span> <span class="k">if</span> <span class="n">has_labels</span> <span class="k">else</span> <span class="p">[]))</span>
  <span class="n">validation_sampler</span> <span class="o">=</span> <span class="n">SequentialSampler</span><span class="p">(</span><span class="n">validation_data</span><span class="p">)</span>
  <span class="n">validation_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_data</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">validation_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">validation_dataloader</span>


<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">has_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Evaluates data from a data loader on a model and returns either a tuple of</span>
<span class="sd">  predicted probability and true label if has_labels=True otherwise it returns</span>
<span class="sd">  the raw logits</span>
<span class="sd">  """</span>
  <span class="c1"># Put model in evaluation mode</span>
  <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

  <span class="c1"># Predict </span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="c1"># Add batch to GPU</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
    <span class="c1"># Unpack the inputs from our dataloader</span>
    <span class="k">if</span> <span class="n">has_labels</span><span class="p">:</span>
      <span class="n">b_input_ids</span><span class="p">,</span> <span class="n">b_input_mask</span><span class="p">,</span> <span class="n">b_labels</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">b_input_ids</span><span class="p">,</span> <span class="n">b_input_mask</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># Telling the model not to compute or store gradients, saving memory and speeding up prediction</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="c1"># Forward pass, calculate logit predictions</span>
      <span class="n">logits</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span><span class="p">)</span>

    <span class="c1"># Move logits and labels to CPU</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">has_labels</span><span class="p">:</span>
      <span class="n">softmax_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logits</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">label_ids</span> <span class="o">=</span> <span class="n">b_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
      <span class="k">for</span> <span class="n">prob</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">softmax_probs</span><span class="p">,</span> <span class="n">label_ids</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">prob</span><span class="p">,</span> <span class="n">label</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">yield</span> <span class="n">logits</span>

  
<span class="k">def</span> <span class="nf">eval_loss_sentences</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="s1">'char'</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Evaluate the loss for a list of sentences</span>
<span class="sd">  sentences: the list of sentences</span>
<span class="sd">  masking: 'word' for whole word, and 'char' for single character masking</span>
<span class="sd">  """</span>
  <span class="k">assert</span> <span class="n">masking</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'word'</span><span class="p">,</span> <span class="s1">'char'</span><span class="p">]</span>
  <span class="n">masking_words</span> <span class="o">=</span> <span class="n">masking</span> <span class="o">==</span> <span class="s1">'word'</span>
  <span class="n">indexed_sentence_tokens</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">tokenized_sentences</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">sentence_mask_indices</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">all_examples</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="c1"># NOTE: the tokenizer removes spaces</span>
    <span class="n">tokenized_sentence</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="n">tokenized_sentence</span> <span class="o">=</span> <span class="n">tokenized_sentence</span><span class="p">[:</span><span class="mi">128</span><span class="p">]</span>
    <span class="n">indexed_sentence_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="n">tokenized_sentence</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">masking_words</span><span class="p">:</span>
      <span class="n">tokenized_sentence</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">jieba</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokenized_sentence</span><span class="p">)))</span>
    <span class="n">tokenized_sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tokenized_sentence</span><span class="p">)</span>
    <span class="n">mask_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">char_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenized_sentence</span><span class="p">)):</span>
      <span class="n">mask_token</span> <span class="o">=</span> <span class="n">tokenized_sentence</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
      <span class="n">mask_token_parts</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">mask_token</span><span class="p">))</span> <span class="k">if</span> <span class="n">masking_words</span> <span class="k">else</span> <span class="mi">1</span>
      <span class="n">all_examples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokenized_sentence</span><span class="p">[:</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span>
                          <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mask_token_parts</span><span class="o">*</span><span class="p">[</span><span class="s1">'[MASK]'</span><span class="p">])</span> <span class="o">+</span>
                          <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokenized_sentence</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:]))</span>
      <span class="n">mask_indices</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">char_idx</span><span class="p">,</span> <span class="n">char_idx</span><span class="o">+</span><span class="n">mask_token_parts</span><span class="p">))</span>
      <span class="n">char_idx</span> <span class="o">+=</span> <span class="n">mask_token_parts</span>
    <span class="n">mask_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'[SEP]'</span><span class="p">)</span>
    <span class="n">sentence_mask_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask_indices</span><span class="p">)</span>

  <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">'sentence'</span><span class="p">:</span> <span class="n">all_examples</span><span class="p">})</span>
  <span class="n">dataloader</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

  <span class="n">sentence_losses</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">curr_sentence_loss</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">curr_sentence</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">curr_mask_idx</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">curr_example</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">batch_logits</span> <span class="ow">in</span> <span class="n">predict</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">masked_lm_model</span><span class="p">,</span> <span class="n">has_labels</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
      <span class="n">mask_start</span><span class="p">,</span> <span class="n">mask_end</span> <span class="o">=</span> <span class="n">sentence_mask_indices</span><span class="p">[</span><span class="n">curr_sentence</span><span class="p">][</span><span class="n">curr_mask_idx</span><span class="p">]</span>
      <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mask_start</span><span class="p">,</span> <span class="n">mask_end</span><span class="p">):</span>
        <span class="n">mask_logits</span> <span class="o">=</span> <span class="n">batch_logits</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">mask_logits_exp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mask_logits</span><span class="p">)</span>
        <span class="n">mask_token_probs</span> <span class="o">=</span> <span class="n">mask_logits_exp</span> <span class="o">/</span> <span class="n">mask_logits_exp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">mask_entropy</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">mask_token_probs</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">mask_token_probs</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">masked_token_index</span> <span class="o">=</span> <span class="n">indexed_sentence_tokens</span><span class="p">[</span><span class="n">curr_sentence</span><span class="p">][</span><span class="n">m</span><span class="p">]</span>
        <span class="c1"># Cross-Entropy Loss</span>
        <span class="n">curr_sentence_loss</span> <span class="o">+=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">mask_token_probs</span><span class="p">[</span><span class="n">masked_token_index</span><span class="p">])</span>

      <span class="n">curr_mask_idx</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="n">curr_example</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="k">if</span> <span class="n">curr_mask_idx</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">[</span><span class="n">curr_sentence</span><span class="p">]):</span>
        <span class="c1"># We've reached a new sentence, reset and append log prob</span>
        <span class="c1"># Normalize sentence loss by number of tokens</span>
        <span class="n">curr_sentence_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">[</span><span class="n">curr_sentence</span><span class="p">])</span>
        <span class="n">sentence_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_sentence_loss</span><span class="p">)</span>
        <span class="n">curr_sentence_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">curr_mask_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">curr_sentence</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="k">return</span> <span class="n">sentence_losses</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Download example sentences from Tatoeba and word frequency dataset:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span> wget http://downloads.tatoeba.org/exports/sentences.tar.bz2
<span class="o">!</span> bzip2 -dc sentences.tar.bz2 &gt; <span class="s2">"</span><span class="nv">$cache_path</span><span class="s2">/sentences.txt"</span>
<span class="o">!</span> wget https://www.plecoforums.com/download/weibo_wordfreq-release_utf-8-txt.2603 -O <span class="s2">"</span><span class="nv">$cache_path</span><span class="s2">/weibo.txt"</span>
</pre></div>

    </div>
</div>
</div>

        
    

    
      
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below is the code for reading the Tatoeba and Weibo frequency datasets and generating hard negatives:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (208 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">orig_sentences</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cache_path</span><span class="o">+</span><span class="s1">'/sentences.txt'</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
      <span class="n">splits</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">splits</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">continue</span>
      <span class="n">_</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">zh</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">lang</span> <span class="o">!=</span> <span class="s1">'cmn'</span><span class="p">:</span> <span class="k">continue</span>
      <span class="n">zh</span> <span class="o">=</span> <span class="n">HanziConv</span><span class="o">.</span><span class="n">toSimplified</span><span class="p">(</span><span class="n">zh</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
      <span class="n">orig_sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zh</span><span class="p">)</span>

<span class="n">words</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">counts</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cache_path</span><span class="o">+</span><span class="s1">'/weibo.txt'</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8-sig'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> 
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
        <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">)</span>
        <span class="n">tokenized_word</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenized_word</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
          <span class="k">continue</span>
        
        <span class="c1"># Skip [UNK] or other garbage unkown to the BERT tokenizer</span>
        <span class="n">skip</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokenized_word</span><span class="p">:</span>
          <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">skip</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">break</span>
        <span class="k">if</span> <span class="n">skip</span><span class="p">:</span> <span class="k">continue</span>
        <span class="n">words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">counts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">count</span><span class="p">))</span>

<span class="c1"># Calculate the probability and cumulative probability function for words over</span>
<span class="c1"># the frequency</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
<span class="n">word_probs</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">counts</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">cdf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">word_probs</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sample_word</span><span class="p">():</span>
  <span class="sd">""" Sample a random word based on frequency """</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">cdf</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">words</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="nd">@lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">middle_coprime</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
  <span class="sd">""" Find the middle coprime of a number, e.g. of all the</span>
<span class="sd">      sorted coprimes of n, pick the middle one """</span>
  <span class="n">factors</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">factorint</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
  <span class="n">coprimes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">coprime</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">factors</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">f</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">coprime</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">break</span>
    <span class="k">if</span> <span class="n">coprime</span><span class="p">:</span>
      <span class="n">coprimes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">coprimes</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">coprimes</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">pseudo_random_range</span><span class="p">(</span><span class="n">from_idx</span><span class="p">,</span> <span class="n">to_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Visit all indices in a range pseudo-randomly by visiting (ax + b) mod n, </span>
<span class="sd">  where a and n are co-prime. Small and large coprimes tend to not look random,</span>
<span class="sd">  so pick the middle one.</span>
<span class="sd">  """</span>
  <span class="k">if</span> <span class="n">to_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">from_idx</span><span class="p">,</span> <span class="n">to_idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">from_idx</span>

  <span class="n">n</span> <span class="o">=</span> <span class="n">to_idx</span> <span class="o">-</span> <span class="n">from_idx</span>
  <span class="n">coprime</span> <span class="o">=</span> <span class="n">middle_coprime</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
  <span class="n">offset</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="k">yield</span> <span class="n">from_idx</span> <span class="o">+</span> <span class="p">(</span><span class="n">coprime</span><span class="o">*</span><span class="n">i</span> <span class="o">+</span> <span class="n">offset</span><span class="p">)</span> <span class="o">%</span> <span class="n">n</span> 


<span class="n">IGNORE</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="s1">'„ÄÇ'</span><span class="p">,</span> <span class="s1">'„Äç'</span><span class="p">,</span> <span class="s1">'„Äå'</span><span class="p">,</span> <span class="s1">'Ôºå'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="s1">'ÔºÅ'</span><span class="p">,</span> <span class="s1">'Ôºü'</span><span class="p">,</span> <span class="s1">'?'</span><span class="p">,</span> <span class="s1">'!'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">,</span> <span class="s1">','</span><span class="p">])</span>
<span class="c1"># Swaps that usually produce acceptable sentences:</span>
<span class="n">POSITIVE_SWAP_GROUPS</span> <span class="o">=</span> <span class="p">[</span><span class="nb">set</span><span class="p">([</span><span class="s1">'Êàë'</span><span class="p">,</span> <span class="s1">'‰Ω†'</span><span class="p">,</span> <span class="s1">'‰ªñ'</span><span class="p">,</span> <span class="s1">'Â•π'</span><span class="p">]),</span> <span class="c1"># personal pronouns</span>
                       <span class="nb">set</span><span class="p">([</span><span class="s1">'Êàë‰ª¨'</span><span class="p">,</span> <span class="s1">'‰Ω†‰ª¨'</span><span class="p">,</span> <span class="s1">'‰ªñ‰ª¨'</span><span class="p">,</span> <span class="s1">'Â•π‰ª¨'</span><span class="p">])]</span> <span class="c1"># plural personal pronouns</span>
<span class="k">def</span> <span class="nf">is_positive_swap</span><span class="p">(</span><span class="n">from_token</span><span class="p">,</span> <span class="n">to_token</span><span class="p">):</span>
  <span class="n">swap_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="n">from_token</span><span class="p">,</span> <span class="n">to_token</span><span class="p">])</span>
  <span class="c1"># Check if both tokens are in a positive swap group, if so we don't swap</span>
  <span class="k">for</span> <span class="n">swap_group</span> <span class="ow">in</span> <span class="n">POSITIVE_SWAP_GROUPS</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">swap_set</span> <span class="o">&amp;</span> <span class="n">swap_group</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">True</span>
  <span class="k">return</span> <span class="kc">False</span>

<span class="k">def</span> <span class="nf">generate_delete</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">pseudo_random_range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)):</span>    
    <span class="n">token</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">IGNORE</span><span class="p">:</span>
      <span class="k">continue</span>
    <span class="n">tokens_deleted</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokens</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">yield</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens_deleted</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_insert</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">pseudo_random_range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)):</span>    
    <span class="n">word</span> <span class="o">=</span> <span class="n">sample_word</span><span class="p">()</span>
    <span class="n">tokens_inserted</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="p">[(</span><span class="n">word</span><span class="p">,)]</span> <span class="o">+</span> <span class="n">tokens</span><span class="p">[</span><span class="n">idx</span><span class="p">:]</span>
    <span class="k">yield</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens_inserted</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_replace</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">pseudo_random_range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)):</span>    
    <span class="n">token</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">IGNORE</span><span class="p">:</span>
      <span class="k">continue</span>
    <span class="c1"># Sample words until it's not equal to the token we're replacing</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">token</span>
    <span class="k">while</span> <span class="n">word</span> <span class="o">==</span> <span class="n">token</span><span class="p">:</span>
      <span class="n">word</span> <span class="o">=</span> <span class="n">sample_word</span><span class="p">()</span>
    <span class="n">tokens_replaced</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="p">[(</span><span class="n">word</span><span class="p">,)]</span> <span class="o">+</span> <span class="n">tokens</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">yield</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens_replaced</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_swap</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
  <span class="n">token_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">])</span>
  <span class="k">for</span> <span class="n">from_idx</span> <span class="ow">in</span> <span class="n">pseudo_random_range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>    
    <span class="n">from_token</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="n">from_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">from_token</span> <span class="ow">in</span> <span class="n">IGNORE</span><span class="p">:</span>
      <span class="k">continue</span>

    <span class="k">for</span> <span class="n">to_idx</span> <span class="ow">in</span> <span class="n">pseudo_random_range</span><span class="p">(</span><span class="n">from_idx</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)):</span>
      <span class="n">to_token</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="n">to_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">from_token</span> <span class="o">==</span> <span class="n">to_token</span> <span class="ow">or</span>
          <span class="n">to_token</span> <span class="ow">in</span> <span class="n">IGNORE</span><span class="p">):</span>
          <span class="k">continue</span>

      <span class="k">if</span> <span class="n">is_positive_swap</span><span class="p">(</span><span class="n">from_token</span><span class="p">,</span> <span class="n">to_token</span><span class="p">):</span>
        <span class="k">continue</span>
        
      <span class="c1"># Swap the tokens and return the new string</span>
      <span class="n">mtokens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
      <span class="n">mtokens</span><span class="p">[</span><span class="n">to_idx</span><span class="p">],</span> <span class="n">mtokens</span><span class="p">[</span><span class="n">from_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">mtokens</span><span class="p">[</span><span class="n">from_idx</span><span class="p">],</span> <span class="n">mtokens</span><span class="p">[</span><span class="n">to_idx</span><span class="p">]</span>
      <span class="k">yield</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">mtokens</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_mutated</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
  <span class="n">tokens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span>
  <span class="n">generators</span> <span class="o">=</span> <span class="p">[</span><span class="c1">#generate_delete(sentence, tokens),</span>
                <span class="n">generate_insert</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">tokens</span><span class="p">),</span>
                <span class="n">generate_replace</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">tokens</span><span class="p">),</span>
                <span class="n">generate_swap</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)]</span>
  <span class="n">pick_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
  <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">generators</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">gen_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">generators</span><span class="p">)),</span> <span class="n">p</span><span class="o">=</span><span class="n">pick_probs</span><span class="p">)</span>
    <span class="n">random_gen</span> <span class="o">=</span> <span class="n">generators</span><span class="p">[</span><span class="n">gen_idx</span><span class="p">]</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="k">yield</span> <span class="nb">next</span><span class="p">(</span><span class="n">random_gen</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
      <span class="c1"># The generator is out of sentences to generate, so remove it</span>
      <span class="k">del</span> <span class="n">generators</span><span class="p">[</span><span class="n">gen_idx</span><span class="p">]</span>
      <span class="n">pick_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">pick_probs</span><span class="p">,</span> <span class="n">gen_idx</span><span class="p">)</span>
      <span class="c1"># Need to normalize so probabilities add up to 1</span>
      <span class="n">pick_probs</span> <span class="o">/=</span> <span class="n">pick_probs</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">generate_hard_negatives</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">generate_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                            <span class="n">debug_print</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Creates hard negative examples, which are sampled based on mutations that</span>
<span class="sd">  increase the loss the least but still significantly enough to very likely be a</span>
<span class="sd">  true negative.</span>
<span class="sd">  """</span>
  <span class="n">sentence_examples</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentence_examples</span><span class="p">):</span>
    <span class="c1"># Skip sentences with unknown words or other garbage</span>
    <span class="n">predict_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span><span class="p">]</span>
    <span class="n">generator</span> <span class="o">=</span> <span class="n">generate_mutated</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">generate_max</span><span class="p">):</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">predict_sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">generator</span><span class="p">))</span>
      <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
        <span class="k">break</span>
    
    <span class="n">losses</span> <span class="o">=</span> <span class="n">eval_loss_sentences</span><span class="p">(</span><span class="n">predict_sentences</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="s1">'char'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'C: '</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">predict_sentences</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">losses</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
      <span class="k">if</span> <span class="n">l</span> <span class="o">-</span> <span class="n">losses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">loss_threshold</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">debug_print</span><span class="p">:</span>
          <span class="nb">print</span><span class="p">(</span><span class="s1">'W: '</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="s1">' +'</span><span class="p">,</span> <span class="n">l</span><span class="o">-</span><span class="n">losses</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">yield</span> <span class="n">s</span>
        <span class="k">break</span>


<span class="n">negatives_path</span> <span class="o">=</span> <span class="n">cache_path</span> <span class="o">+</span> <span class="s1">'/negatives.txt'</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">negatives_path</span><span class="p">):</span>
  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">negatives_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">hard_negatives</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
<span class="k">else</span><span class="p">:</span>
  <span class="c1"># NOTE: generating hard negatives takes a long time since to check a single mutation</span>
  <span class="c1"># we need to run inference len(sentence) times, and we need to generate a number</span>
  <span class="c1"># of mutations for each sentence in order to find a good one</span>
  <span class="c1"># So we run a few thousand at a time and store them in case runtime gets recycled</span>
  <span class="n">use_num</span> <span class="o">=</span> <span class="mi">30000</span>
  <span class="n">num_at_a_time</span> <span class="o">=</span> <span class="mi">3000</span>
  <span class="n">use_sentences</span> <span class="o">=</span> <span class="n">orig_sentences</span><span class="p">[:</span><span class="n">use_num</span><span class="p">]</span>
  <span class="n">hard_negatives</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">use_num</span> <span class="o">//</span> <span class="n">num_at_a_time</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">f</span><span class="s1">'</span><span class="si">{cache_path}</span><span class="s1">/negatives{i+1}.txt'</span><span class="p">):</span>
      <span class="k">continue</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">f</span><span class="s1">'</span><span class="si">{cache_path}</span><span class="s1">/negatives{i+1}.txt'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
      <span class="n">sentences</span> <span class="o">=</span> <span class="n">use_sentences</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">num_at_a_time</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">num_at_a_time</span><span class="p">]</span>
      <span class="k">for</span> <span class="n">negative</span> <span class="ow">in</span> <span class="n">generate_hard_negatives</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">masked_lm_model</span><span class="p">,</span> <span class="n">debug_print</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">hard_negatives</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">negative</span><span class="p">)</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">negative</span> <span class="o">+</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

  <span class="c1"># Concatenate all files to one</span>
  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">negatives_path</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">n</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">use_num</span> <span class="o">//</span> <span class="n">num_at_a_time</span><span class="p">):</span>
      <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">f</span><span class="s1">'</span><span class="si">{cache_path}</span><span class="s1">/negatives{i+1}.txt'</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">n</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fine-tuning-BERT">Fine-tuning BERT<a class="anchor-link" href="can-i-say-this/#Fine-tuning-BERT">¬∂</a>
</h3>
<p>There are plenty of tutorials on how to fine-tune a BERT model. For this experiment I'll use the pre-trained Chinese model in the Python library <a href="https://github.com/huggingface/transformers">pytorch-transformers</a> by huggingface. This model is trained with a character-by-character tokenizer, meaning multi-character Chinese words are split into separate word embeddings for each character. This may be <a href="https://github.com/ymcui/Chinese-BERT-wwm/blob/master/README_EN.md">suboptimal</a>, unless the model is powerful enough to capture the structure of words, but for now this is what we have to work with.</p>
<p>Below is the code for training and validating the BERT model for classification:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (72 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">debug_print</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"bert-base-chinese"</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">);</span>
    <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

  <span class="n">param_optimizer</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())</span>
  <span class="n">no_decay</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'bias'</span><span class="p">,</span> <span class="s1">'gamma'</span><span class="p">,</span> <span class="s1">'beta'</span><span class="p">]</span>
  <span class="n">optimizer_grouped_parameters</span> <span class="o">=</span> <span class="p">[</span>
      <span class="p">{</span><span class="s1">'params'</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">param_optimizer</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">nd</span> <span class="ow">in</span> <span class="n">n</span> <span class="k">for</span> <span class="n">nd</span> <span class="ow">in</span> <span class="n">no_decay</span><span class="p">)],</span>
       <span class="s1">'weight_decay_rate'</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">},</span>
      <span class="p">{</span><span class="s1">'params'</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">param_optimizer</span> <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">nd</span> <span class="ow">in</span> <span class="n">n</span> <span class="k">for</span> <span class="n">nd</span> <span class="ow">in</span> <span class="n">no_decay</span><span class="p">)],</span>
       <span class="s1">'weight_decay_rate'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
  <span class="p">]</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">optimizer_grouped_parameters</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">)</span>
  
  <span class="c1"># Set our model to training mode (as opposed to evaluation mode)</span>
  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
  <span class="n">train_loss_set</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1"># trange is a tqdm wrapper around the normal python range which prints progress</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">"Epoch"</span><span class="p">)</span> <span class="k">if</span> <span class="n">debug_print</span> <span class="k">else</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">r</span><span class="p">:</span>
    <span class="c1"># Tracking variables</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">num_examples</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="c1"># Train the data for one epoch</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">debug_print</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'Batch: </span><span class="si">{step}</span><span class="s1">'</span><span class="p">)</span>
      <span class="c1"># Add batch to GPU</span>
      <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
      <span class="c1"># Unpack the inputs from our dataloader</span>
      <span class="n">b_input_ids</span><span class="p">,</span> <span class="n">b_input_mask</span><span class="p">,</span> <span class="n">b_labels</span> <span class="o">=</span> <span class="n">batch</span>
      <span class="c1"># Clear out the gradients (by default they accumulate)</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="c1"># Forward pass</span>
      <span class="n">loss</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">b_labels</span><span class="p">)</span>
      <span class="n">train_loss_set</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>    
      <span class="c1"># Backward pass</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="c1"># Update parameters and take a step using the computed gradient</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="c1"># Update tracking variables</span>
      <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
      <span class="n">num_examples</span> <span class="o">+=</span> <span class="n">b_input_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="n">num_steps</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">debug_print</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">"Train loss: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_loss</span><span class="o">/</span><span class="n">num_steps</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">prob</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">predict</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
      <span class="n">y_true</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
      <span class="n">y_pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">prob</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span>


<span class="k">def</span> <span class="nf">print_stats</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sentences</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="n">tab</span> <span class="o">=</span> <span class="s1">''</span>
  <span class="k">if</span> <span class="n">label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'</span><span class="si">{label}</span><span class="s1">:'</span><span class="p">)</span>
    <span class="n">tab</span> <span class="o">=</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'</span><span class="si">{tab}</span><span class="s1">Matthews Correlaton Coefficient:'</span><span class="p">,</span> <span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'</span><span class="si">{tab}</span><span class="s1">Accuracy:'</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'</span><span class="si">{tab}</span><span class="s1">Precision:'</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'</span><span class="si">{tab}</span><span class="s1">Recall:'</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can train our first classification model on positive examples from the Tatoeba dataset and our generated hard negatives. Here I'll train the classifier with an increasing number of examples to see if we need more data. Training an iterating is slow, so I prefer to keep it as small as possible for now.</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (28 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_path</span> <span class="o">=</span> <span class="n">cache_path</span> <span class="o">+</span> <span class="s1">'/self_supervised_classification_model.pt'</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
  <span class="n">classification_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">training_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">validation_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">classification_model</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3000</span><span class="p">,</span> <span class="mi">6000</span><span class="p">,</span> <span class="mi">9000</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hard_negatives</span><span class="p">)]:</span>
    <span class="n">hard_negatives_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">'sentence'</span><span class="p">:</span> <span class="n">hard_negatives</span><span class="p">[:</span><span class="n">num</span><span class="p">]</span> <span class="o">+</span> <span class="n">orig_sentences</span><span class="p">[</span><span class="n">num</span><span class="p">:</span><span class="mi">2</span><span class="o">*</span><span class="n">num</span><span class="p">],</span>
        <span class="s1">'orig'</span><span class="p">:</span> <span class="n">orig_sentences</span><span class="p">[:</span><span class="mi">2</span><span class="o">*</span><span class="n">num</span><span class="p">],</span>
        <span class="s1">'label'</span><span class="p">:</span> <span class="n">num</span><span class="o">*</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">num</span><span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">]})</span>

    <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">validation_dataloader</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span>
        <span class="n">hard_negatives_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    
    <span class="n">classification_model</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">debug_print</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Train accuracy: '</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">(</span><span class="o">*</span><span class="n">evaluate</span><span class="p">(</span><span class="n">classification_model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Validation accuracy: '</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">(</span><span class="o">*</span><span class="n">evaluate</span><span class="p">(</span><span class="n">classification_model</span><span class="p">,</span> <span class="n">validation_dataloader</span><span class="p">)))</span>
  
  <span class="c1"># Save to disk, for rerunning and making copies</span>
  <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">classification_model</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'sentence'</span><span class="p">:</span> <span class="n">hard_negatives</span> <span class="o">+</span> <span class="n">orig_sentences</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">hard_negatives</span><span class="p">):</span><span class="mi">2</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">hard_negatives</span><span class="p">)],</span>
    <span class="s1">'label'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">hard_negatives</span><span class="p">)</span><span class="o">*</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">hard_negatives</span><span class="p">)</span><span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">]})</span>
<span class="n">dataloader</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">print_stats</span><span class="p">(</span><span class="o">*</span><span class="n">evaluate</span><span class="p">(</span><span class="n">classification_model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Final'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's load the AllSet grammatical wiki examples and train models with cross-validation either from scratch or using the pre-trained model.</p>
<p>One important difference from the previous dataset is that we want to know how well the model generalizes to new <em>unseen</em> grammatical rules rather than just unseen examples. Therefore we split the data into training and validation sets based on the grammatical rule/group, such that examples from the same group never are split between the train and test sets.</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (89 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">allset_negative_examples</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cache_path</span><span class="o">+</span><span class="s1">'/allset_negative_examples.txt'</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
    <span class="n">filename</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">':'</span><span class="p">)</span>
    <span class="n">allset_negative_examples</span><span class="p">[</span><span class="n">filename</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
<span class="n">allset_positive_examples</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cache_path</span><span class="o">+</span><span class="s1">'/allset_positive_examples.txt'</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
    <span class="n">filename</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">':'</span><span class="p">)</span>
    <span class="n">allset_positive_examples</span><span class="p">[</span><span class="n">filename</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>

<span class="n">all_files</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">allset_negative_examples</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">|</span>
                 <span class="nb">set</span><span class="p">(</span><span class="n">allset_positive_examples</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
<span class="n">allset_sentences</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">allset_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">allset_groups</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">g</span><span class="p">,</span> <span class="n">filename</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_files</span><span class="p">):</span>
  <span class="n">negative</span> <span class="o">=</span> <span class="n">allset_negative_examples</span><span class="p">[</span><span class="n">filename</span><span class="p">]</span>
  <span class="n">positive</span> <span class="o">=</span> <span class="n">allset_positive_examples</span><span class="p">[</span><span class="n">filename</span><span class="p">]</span>
  <span class="n">allset_sentences</span> <span class="o">+=</span> <span class="n">negative</span> <span class="o">+</span> <span class="n">positive</span>
  <span class="n">allset_labels</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">negative</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">positive</span><span class="p">)</span>
  <span class="n">allset_groups</span> <span class="o">+=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">negative</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">positive</span><span class="p">))</span><span class="o">*</span><span class="p">[</span><span class="n">g</span><span class="p">]</span>

<span class="n">allset_sentences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">allset_sentences</span><span class="p">)</span>
<span class="n">allset_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">allset_labels</span><span class="p">)</span>
<span class="n">allset_groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">allset_groups</span><span class="p">)</span>

<span class="n">tatoeba_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">orig_sentences</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">hard_negative_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">hard_negatives</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">self_supervised_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'sentence'</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">hard_negative_sample</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">tatoeba_sample</span><span class="p">),</span>
    <span class="s1">'label'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">hard_negative_sample</span><span class="p">)</span><span class="o">*</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">tatoeba_sample</span><span class="p">)</span><span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">]})</span>
<span class="n">self_supervised_dataloader</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">self_supervised_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                             <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cross_validate_allset</span><span class="p">(</span><span class="n">initial_model_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                          <span class="n">print_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="n">train_results</span> <span class="o">=</span> <span class="p">[[],</span> <span class="p">[]]</span>
  <span class="n">test_results</span> <span class="o">=</span> <span class="p">[[],</span> <span class="p">[]]</span>
  <span class="n">self_supervised_results</span> <span class="o">=</span> <span class="p">[[],</span> <span class="p">[]]</span>
  <span class="n">new_model</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="k">if</span> <span class="n">n_splits</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">generator</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">allset_sentences</span><span class="p">)),</span>
                 <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">allset_sentences</span><span class="p">)))]</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">group_kfold</span> <span class="o">=</span> <span class="n">GroupKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">)</span>
    <span class="n">generator</span> <span class="o">=</span> <span class="n">group_kfold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">allset_sentences</span><span class="p">,</span> <span class="n">allset_labels</span><span class="p">,</span> <span class="n">allset_groups</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">generator</span><span class="p">):</span>
    <span class="n">train_examples</span> <span class="o">=</span> <span class="n">allset_sentences</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
    <span class="n">train_labels</span> <span class="o">=</span> <span class="n">allset_labels</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
    <span class="n">test_examples</span> <span class="o">=</span> <span class="n">allset_sentences</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">test_labels</span> <span class="o">=</span> <span class="n">allset_labels</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
  
    <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">'sentence'</span><span class="p">:</span> <span class="n">train_examples</span><span class="p">,</span> <span class="s1">'label'</span><span class="p">:</span> <span class="n">train_labels</span><span class="p">}),</span>
        <span class="n">test_size</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">'sentence'</span><span class="p">:</span> <span class="n">test_examples</span><span class="p">,</span> <span class="s1">'label'</span><span class="p">:</span> <span class="n">test_labels</span><span class="p">}),</span>
        <span class="n">test_size</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
  
    <span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">initial_model_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">initial_model_path</span><span class="p">)</span>

    <span class="n">new_model</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                      <span class="n">debug_print</span><span class="o">=</span><span class="n">print_progress</span><span class="p">)</span>
    
    <span class="n">train_result</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">new_model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">)</span>
    <span class="n">test_result</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">new_model</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="p">)</span>
    <span class="n">self_supervised_result</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">new_model</span><span class="p">,</span> <span class="n">self_supervised_dataloader</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">print_progress</span><span class="p">:</span>
      <span class="n">print_stats</span><span class="p">(</span><span class="o">*</span><span class="n">train_result</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'AllSet Train'</span><span class="p">)</span>
      <span class="n">print_stats</span><span class="p">(</span><span class="o">*</span><span class="n">test_result</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'AllSet Test'</span><span class="p">)</span>
      <span class="n">print_stats</span><span class="p">(</span><span class="o">*</span><span class="n">self_supervised_result</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Self-Supervised'</span><span class="p">)</span>

    <span class="n">train_results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">train_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">train_results</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">train_result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">test_results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">test_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">test_results</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">test_result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">self_supervised_results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">self_supervised_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">self_supervised_results</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">self_supervised_result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  
  <span class="n">print_stats</span><span class="p">(</span><span class="o">*</span><span class="n">train_result</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Overall AllSet Train'</span><span class="p">)</span>
  <span class="n">print_stats</span><span class="p">(</span><span class="o">*</span><span class="n">test_result</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Overall AllSet Test'</span><span class="p">)</span>
  <span class="n">print_stats</span><span class="p">(</span><span class="o">*</span><span class="n">self_supervised_result</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Overall Self-Supervised'</span><span class="p">)</span>

  <span class="c1"># Return the last model</span>
  <span class="k">return</span> <span class="n">new_model</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First, let's train a model from scratch on the AllSet data and see how well it does against against itself as well as against our self-supervised Tatoeba + Hard negative dataset:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cross_validate_allset</span><span class="p">(</span><span class="n">initial_model_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">print_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Overall AllSet Train:
	Matthews Correlaton Coefficient: 0.978298651254621
	Accuracy: 0.9891304347826086
	Precision: 0.9838337182448037
	Recall: 0.9953271028037384
Overall AllSet Test:
	Matthews Correlaton Coefficient: 0.9366607354497857
	Accuracy: 0.967391304347826
	Precision: 0.94
	Recall: 1.0
Overall Self-Supervised:
	Matthews Correlaton Coefficient: 0.46815654446892113
	Accuracy: 0.7165
	Precision: 0.6568613244457325
	Recall: 0.9066
</pre>
</div>
</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see, it seems to generalize well on the AllSet data across the folds, meaning somehow it generalizes to unseen grammatical rules. But the performance on the self-supervised dataset is poor. This is probably due to the AllSet data being biased towards easier, illustrative examples, which are substantially different from the average sentence from Tatoeba. It also doesn't cover all the more "obvious" ways sentences can be grammatical.</p>
<p>Now lets do the same thing, but with a model pre-trained on the self-supervised dataset, with the hope that we can generalize on both data sets:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cross_validate_allset</span><span class="p">(</span><span class="n">initial_model_path</span><span class="o">=</span><span class="n">model_path</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">print_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Overall AllSet Train:
	Matthews Correlaton Coefficient: 0.9927488225424451
	Accuracy: 0.9963768115942029
	Precision: 0.9976580796252927
	Recall: 0.9953271028037384
Overall AllSet Test:
	Matthews Correlaton Coefficient: 0.9784719757905218
	Accuracy: 0.9891304347826086
	Precision: 0.9791666666666666
	Recall: 1.0
Overall Self-Supervised:
	Matthews Correlaton Coefficient: 0.8895640148971811
	Accuracy: 0.94365
	Precision: 0.9777107785075912
	Recall: 0.908
</pre>
</div>
</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The overall results show that the model has generalized relatively well to both datasets, although the scores are lower for the self-supervised data set compared to before.</p>
<p>For training the final model, we can get an even better result for the self-supervised data by training it from scratch on both data sets, but with the AllSet data upsampled to match the self-supervised in size, giving both equal importance. Here I'll train it once with a single test set instead of k-fold cross validation, so I don't time out in Google Colab.</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (45 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">final_model_path</span> <span class="o">=</span> <span class="n">cache_path</span><span class="o">+</span><span class="s1">'/final_model.pt'</span> 
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">final_model_path</span><span class="p">):</span>
  <span class="n">final_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">final_model_path</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="c1"># Again, need to split AllSet into train/test using GroupKFold</span>
  <span class="c1"># GroupKFold.split returns all cross-validation sets, but we'll just use the first</span>
  <span class="n">allset_train_idx</span><span class="p">,</span> <span class="n">allset_test_idx</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">GroupKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">allset_sentences</span><span class="p">,</span> <span class="n">allset_labels</span><span class="p">,</span> <span class="n">allset_groups</span><span class="p">))</span>
  <span class="n">allset_train</span> <span class="o">=</span> <span class="n">allset_sentences</span><span class="p">[</span><span class="n">allset_train_idx</span><span class="p">]</span>
  <span class="n">allset_train_labels</span> <span class="o">=</span> <span class="n">allset_labels</span><span class="p">[</span><span class="n">allset_train_idx</span><span class="p">]</span>
  <span class="n">allset_test</span> <span class="o">=</span> <span class="n">allset_sentences</span><span class="p">[</span><span class="n">allset_test_idx</span><span class="p">]</span>
  <span class="n">allset_test_labels</span> <span class="o">=</span> <span class="n">allset_labels</span><span class="p">[</span><span class="n">allset_test_idx</span><span class="p">]</span>
  
  <span class="c1"># Next split the self-supervised data set into train/test as well</span>
  <span class="n">ss_train</span><span class="p">,</span> <span class="n">ss_test</span><span class="p">,</span> <span class="n">ss_train_labels</span><span class="p">,</span> <span class="n">ss_test_labels</span> <span class="o">=</span>  <span class="n">train_test_split</span><span class="p">(</span>
      <span class="n">orig_sentences</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">hard_negatives</span><span class="p">):</span><span class="mi">2</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">hard_negatives</span><span class="p">)]</span> <span class="o">+</span> <span class="n">hard_negatives</span><span class="p">,</span>
      <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">hard_negatives</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">hard_negatives</span><span class="p">),</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
  
  <span class="c1"># Then combine both data sets, but with upsampling for AllSet so that they are</span>
  <span class="c1"># of equal size</span>
  <span class="n">upsample_times</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">hard_negatives</span><span class="p">)</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">allset_sentences</span><span class="p">)</span>
  <span class="n">all_train</span> <span class="o">=</span> <span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">ss_train</span><span class="p">)</span> <span class="o">+</span> <span class="n">upsample_times</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">allset_train</span><span class="p">))</span>
  <span class="n">all_train_labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">ss_train_labels</span> <span class="o">+</span> <span class="n">upsample_times</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">allset_train_labels</span><span class="p">))</span>
  
  <span class="n">all_train_dataloader</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span>
      <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">'sentence'</span><span class="p">:</span> <span class="n">all_train</span><span class="p">,</span> <span class="s1">'label'</span><span class="p">:</span> <span class="n">all_train_labels</span><span class="p">}),</span>
      <span class="n">test_size</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
  <span class="n">allset_test_dataloader</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span>
      <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">'sentence'</span><span class="p">:</span> <span class="n">allset_test</span><span class="p">,</span> <span class="s1">'label'</span><span class="p">:</span> <span class="n">allset_test_labels</span><span class="p">}),</span>
      <span class="n">test_size</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
  <span class="n">ss_test_dataloader</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span>
      <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">'sentence'</span><span class="p">:</span> <span class="n">ss_test</span><span class="p">,</span> <span class="s1">'label'</span><span class="p">:</span> <span class="n">ss_test_labels</span><span class="p">}),</span>
      <span class="n">test_size</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
  
  <span class="n">final_model</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">all_train_dataloader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                      <span class="n">model</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">),</span>
                      <span class="n">debug_print</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  
  <span class="n">train_result</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">final_model</span><span class="p">,</span> <span class="n">all_train_dataloader</span><span class="p">)</span>
  <span class="n">allset_test_result</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">final_model</span><span class="p">,</span> <span class="n">allset_test_dataloader</span><span class="p">)</span>
  <span class="n">ss_test_result</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">final_model</span><span class="p">,</span> <span class="n">ss_test_dataloader</span><span class="p">)</span>
  <span class="n">print_stats</span><span class="p">(</span><span class="o">*</span><span class="n">train_result</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
  <span class="n">print_stats</span><span class="p">(</span><span class="o">*</span><span class="n">allset_test_result</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'AllSet Test'</span><span class="p">)</span>
  <span class="n">print_stats</span><span class="p">(</span><span class="o">*</span><span class="n">ss_test_result</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Self-Supervised Test'</span><span class="p">)</span>
  <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">final_model</span><span class="p">,</span> <span class="n">final_model_path</span><span class="p">)</span>
  
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And a sanity check on a few new examples I've found by googling, and some I've come up with myself:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (42 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">incorrect_sentences</span> <span class="o">=</span> <span class="p">[</span>
  <span class="s1">'‰Ω†ÊúâÊ≤°ÊúâËΩ¶ÂêóÔºü'</span><span class="p">,</span>
  <span class="s1">'‰Ω†ÊòØÂæàÈ´ò'</span><span class="p">,</span>
  <span class="s1">'‰Ω†ÂæóÂåÖÂæàÊºÇ‰∫Æ'</span><span class="p">,</span>
  <span class="s1">'Ëøô‰∏™ËΩ¶ÂæàË¥µ'</span><span class="p">,</span>
  <span class="s1">'ËøôÊú¨ËΩ¶ÂæàË¥µ'</span><span class="p">,</span>
  <span class="s1">'ÊàëÁ¢∞Âà∞‰ªñÂú®ÂÖ¨Âõ≠Êò®Â§©‰∫Ü'</span><span class="p">,</span>
  <span class="s1">'Âú®‰∏ÄÂÆ∂‰∏≠ÂõΩÈ•≠Â∫óÔºåÈ©¨‰∏ΩËßÅÈù¢‰∫ÜÊ±§ÂßÜ„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'‰ªñ‰ª¨Âú®Ê≥ïÂõΩËßÅÈù¢‰∫ÜÂØπÊñπ„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'È©¨‰∏ΩÁªìÂ©ö‰∫ÜÊ±§ÂßÜ„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'Ê±§ÂßÜÁªìÂ©ö‰∫ÜÈ©¨‰∏Ω„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'ÊàëÂñúÊ¨¢ÈÉΩÂ≠¶Áîü„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'ËøôÊòØÊàëÁöÑÈÉΩ„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'Êàë‰ª¨ÂºÄ‰ºöÂú®ÊòéÂ§©‰∏äÂçà‰πùÁÇπ „ÄÇ'</span><span class="p">,</span>
  <span class="s1">'Êàë‰∏çÊúâÊó∂Èó¥„ÄÇ'</span>
<span class="p">]</span>
<span class="n">correct_sentences</span> <span class="o">=</span> <span class="p">[</span>
  <span class="s1">'‰Ω†ÊúâÊ≤°ÊúâËΩ¶'</span><span class="p">,</span>
  <span class="s1">'‰Ω†ÂæàÈ´ò'</span><span class="p">,</span>
  <span class="s1">'‰Ω†ÁöÑÂåÖÂæàÊºÇ‰∫Æ'</span><span class="p">,</span>
  <span class="s1">'ËøôËæÜËΩ¶ÂæàË¥µ'</span><span class="p">,</span>
  <span class="s1">'ËøôËæÜËΩ¶ÂæàË¥µ'</span><span class="p">,</span>
  <span class="s1">'ÊàëÊò®Â§©Âú®ÂÖ¨Âõ≠Á¢∞Âà∞‰ªñ‰∫Ü'</span><span class="p">,</span>
  <span class="s1">'Âú®‰∏ÄÂÆ∂‰∏≠ÂõΩÈ•≠Â∫óÔºåÈ©¨‰∏ΩÂíåÊ±§ÂßÜËßÅÈù¢‰∫Ü„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'‰ªñ‰ª¨Âú®Ê≥ïÂõΩÂíåÂØπÊñπËßÅÈù¢‰∫Ü„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'È©¨‰∏ΩÂ´Å‰∫ÜÊ±§ÂßÜ„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'Ê±§ÂßÜÂ®∂‰∫ÜÈ©¨‰∏Ω„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'ÊàëÂñúÊ¨¢ÊâÄÊúâÂ≠¶Áîü„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'ËøôÊòØÊàëÁöÑÊâÄÊúâ„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'Êàë‰ª¨ÊòéÂ§©‰∏äÂçà‰πùÁÇπÂºÄ‰ºö„ÄÇ'</span><span class="p">,</span>
  <span class="s1">'ÊàëÊ≤°ÊúâÊó∂Èó¥„ÄÇ'</span>
<span class="p">]</span>

<span class="n">incorrect_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">'sentence'</span><span class="p">:</span> <span class="n">incorrect_sentences</span><span class="p">,</span> <span class="s1">'label'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">incorrect_sentences</span><span class="p">)</span><span class="o">*</span><span class="p">[</span><span class="mi">0</span><span class="p">]})</span>
<span class="n">incorrect_dataloader</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">incorrect_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">correct_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">'sentence'</span><span class="p">:</span> <span class="n">correct_sentences</span><span class="p">,</span> <span class="s1">'label'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">correct_sentences</span><span class="p">)</span><span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">]})</span>
<span class="n">correct_dataloader</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">correct_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">gen</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">correct_sentences</span><span class="p">,</span> <span class="n">predict</span><span class="p">(</span><span class="n">correct_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">final_model</span><span class="p">,</span> <span class="n">has_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
          <span class="n">incorrect_sentences</span><span class="p">,</span> <span class="n">predict</span><span class="p">(</span><span class="n">incorrect_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">final_model</span><span class="p">,</span> <span class="n">has_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Correct | Incorrect'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">correct</span><span class="p">,</span> <span class="p">(</span><span class="n">prob_correct</span><span class="p">,</span> <span class="n">_</span><span class="p">),</span> <span class="n">incorrect</span><span class="p">,</span> <span class="p">(</span><span class="n">prob_incorrect</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="n">gen</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'</span><span class="si">{correct}</span><span class="s1">: </span><span class="si">{prob_correct:.2f}</span><span class="s1"> | </span><span class="si">{incorrect}</span><span class="s1">: </span><span class="si">{prob_incorrect:.2f}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Correct | Incorrect
‰Ω†ÊúâÊ≤°ÊúâËΩ¶: 1.00 | ‰Ω†ÊúâÊ≤°ÊúâËΩ¶ÂêóÔºü: 0.29
‰Ω†ÂæàÈ´ò: 1.00 | ‰Ω†ÊòØÂæàÈ´ò: 0.02
‰Ω†ÁöÑÂåÖÂæàÊºÇ‰∫Æ: 1.00 | ‰Ω†ÂæóÂåÖÂæàÊºÇ‰∫Æ: 0.00
ËøôËæÜËΩ¶ÂæàË¥µ: 1.00 | Ëøô‰∏™ËΩ¶ÂæàË¥µ: 1.00
ËøôËæÜËΩ¶ÂæàË¥µ: 1.00 | ËøôÊú¨ËΩ¶ÂæàË¥µ: 1.00
ÊàëÊò®Â§©Âú®ÂÖ¨Âõ≠Á¢∞Âà∞‰ªñ‰∫Ü: 0.87 | ÊàëÁ¢∞Âà∞‰ªñÂú®ÂÖ¨Âõ≠Êò®Â§©‰∫Ü: 0.00
Âú®‰∏ÄÂÆ∂‰∏≠ÂõΩÈ•≠Â∫óÔºåÈ©¨‰∏ΩÂíåÊ±§ÂßÜËßÅÈù¢‰∫Ü„ÄÇ: 1.00 | Âú®‰∏ÄÂÆ∂‰∏≠ÂõΩÈ•≠Â∫óÔºåÈ©¨‰∏ΩËßÅÈù¢‰∫ÜÊ±§ÂßÜ„ÄÇ: 0.01
‰ªñ‰ª¨Âú®Ê≥ïÂõΩÂíåÂØπÊñπËßÅÈù¢‰∫Ü„ÄÇ: 1.00 | ‰ªñ‰ª¨Âú®Ê≥ïÂõΩËßÅÈù¢‰∫ÜÂØπÊñπ„ÄÇ: 0.00
È©¨‰∏ΩÂ´Å‰∫ÜÊ±§ÂßÜ„ÄÇ: 0.84 | È©¨‰∏ΩÁªìÂ©ö‰∫ÜÊ±§ÂßÜ„ÄÇ: 0.00
Ê±§ÂßÜÂ®∂‰∫ÜÈ©¨‰∏Ω„ÄÇ: 1.00 | Ê±§ÂßÜÁªìÂ©ö‰∫ÜÈ©¨‰∏Ω„ÄÇ: 0.00
ÊàëÂñúÊ¨¢ÊâÄÊúâÂ≠¶Áîü„ÄÇ: 1.00 | ÊàëÂñúÊ¨¢ÈÉΩÂ≠¶Áîü„ÄÇ: 0.00
ËøôÊòØÊàëÁöÑÊâÄÊúâ„ÄÇ: 1.00 | ËøôÊòØÊàëÁöÑÈÉΩ„ÄÇ: 0.02
Êàë‰ª¨ÊòéÂ§©‰∏äÂçà‰πùÁÇπÂºÄ‰ºö„ÄÇ: 1.00 | Êàë‰ª¨ÂºÄ‰ºöÂú®ÊòéÂ§©‰∏äÂçà‰πùÁÇπ „ÄÇ: 0.58
ÊàëÊ≤°ÊúâÊó∂Èó¥„ÄÇ: 1.00 | Êàë‰∏çÊúâÊó∂Èó¥„ÄÇ: 0.00
</pre>
</div>
</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For those of you who don't know any Chinese, I'll explain the 3 false positives out of these examples.</p>
<p>The first two false positives are when using the wrong "measure word" for the noun "car". In English we have measure words for some things, like a <em>pair</em> of shoes or a <em>loaf</em> of bread, but Chinese loads of them. It seems like the model hasn't managed to learn this, but it's also a simple thing to add more data for: we can just find sentences with measure words and swap them for the wrong one.</p>
<p>The last error is one of sentence word ordering, where in Chinese the time and place always comes first in a sentence. Getting this wrong is a bit suprising, but it also had a probability of 0.58, so at least it's not very sure about it.</p>

</div>
</div>
</div>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="chinese-placement-test/" class="u-url">Chinese Placement Test with Logistic Regression and Active Learning</a></h1>
        <div class="metadata">
            <p class="dateline"><a href="chinese-placement-test/" rel="bookmark"><time class="post-date published dt-published" datetime="2019-09-09T21:09:01+10:00" title="2019-09-09 21:09">2019-09-09 21:09</time></a></p>
                <p class="commentline">
        
    <a href="chinese-placement-test/#disqus_thread" data-disqus-identifier="cache/posts/chinese_placement_test.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>An interesting problem with language learning apps is how to estimate the prior knowledge, the vocabulary, of a new user. Unless the user is a complete beginner, they will come with at least some level of prior knowledge in Chinese. Specifying exactly what you know is too much effort if you know tons of words.</p>
<p>Many content sites divide up content by HSK level (Hanyu Shuiping Kaoshi). For those unfamiliar with Chinese or the HSK, it's a set of standardized test where each level comes with a set of required words. For each level the number of new words roughly doubles (150, 150, 300, 600, 1300 and 2500).</p>
<p>Given the popularity of teaching to the test, the use of these levels in teaching material and apps is pretty ubiquitous. But dividing content based on HSK level is a pretty crude measure. What happens when you're between levels? Then you're bound to over or underestimate the number of words by quite a bit, especially for higher levels. It also doesn't say anything about the words outside the HSK. This is a problem for people like me, who don't follow the HSK very closely, but instead learn words as I come across them in various materials.</p>
<p>So for this little experiement, I'd like to be able to estimate the probability of a user knowing <em>any</em> word in the Chinese language, given a <em>much smaller</em> sample of the user's knowledge. Hopefully, the solution I'll present here could be applied to any kind of learning application where there are some properties of the atomic pieces of information that could be used to predict knowledge.</p>
<h3 id="What-do-we-know-about-words?">What do we know about words?<a class="anchor-link" href="chinese-placement-test/#What-do-we-know-about-words?">¬∂</a>
</h3>
<p>In order to predict the word probabilities we need some features to base the prediction on. Two features pop out immediately: HSK level (duh...) and word frequency in the language. Roughly speaking, you'd expect higher HSK words to be lower frequency words, but as it turns out, the HSK levels aren't that clear cut. And even though the features are correlated, the HSK level carries additional information, since learners are very likely to use learning material that follow it.</p>
<p>Before analyzing word frequencies and HSK words, we need to load a dictionary, a list of word frequencies and HSK words. If you wish to read the code, just click "show code" below:</p>

</div>
</div>
</div>
  
  
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (167 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="k">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="k">import</span> <span class="n">combinations</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">textwrap</span> <span class="k">import</span> <span class="n">wrap</span>

<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="k">import</span> <span class="n">display</span>

<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1">#-----------------------------------------------------------------------</span>
<span class="c1"># Load the Cedict dictionary</span>
<span class="c1">#-----------------------------------------------------------------------</span>
<span class="n">dictionary</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="n">filter_out_patterns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">'see '</span><span class="p">,</span>
    <span class="s1">'abbr. for '</span><span class="p">,</span>
    <span class="s1">'see also '</span><span class="p">,</span>
    <span class="s1">'also written '</span><span class="p">,</span>
    <span class="s1">'euphemistic variant of'</span><span class="p">,</span>
    <span class="s1">'variant of '</span><span class="p">,</span>
    <span class="s1">'unofficial variant of '</span><span class="p">,</span>
    <span class="s1">'archaic variant of '</span><span class="p">,</span>
    <span class="s1">'old variant of '</span><span class="p">,</span>
    <span class="s1">'ancient variant of '</span><span class="p">,</span>
    <span class="s1">'erhua variant of '</span><span class="p">,</span>
    <span class="s1">'Japanese variant of '</span><span class="p">,</span>
    <span class="s1">'CL:'</span><span class="p">,</span>
    <span class="s1">'(old)'</span><span class="p">,</span>
    <span class="s1">'(dialect)'</span><span class="p">,</span>
    <span class="s1">'(surname)'</span><span class="p">,</span>
    <span class="s1">'(Cantonese)'</span><span class="p">,</span>
    <span class="s1">'radical'</span><span class="p">,</span>
    <span class="s1">'Mandarin equivalent'</span>
<span class="p">]</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'cedict_ts.u8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">'#'</span><span class="p">):</span> <span class="c1"># Skip comments</span>
            <span class="k">continue</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">hz</span><span class="p">,</span> <span class="n">py</span><span class="p">,</span> <span class="n">transl</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span>
            <span class="sa">r</span><span class="s2">"(\S*) (\S*) \[(.*)\] \/(.*)\/"</span><span class="p">,</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">groups</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">py</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">isupper</span><span class="p">():</span>
            <span class="k">continue</span> <span class="c1"># Skip named entities</span>

        <span class="n">t_split</span> <span class="o">=</span> <span class="n">transl</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'/'</span><span class="p">)</span>
        <span class="n">t_filtered</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">t_split</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">'surname '</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="n">not_note_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">'[\w\W]*\([\w\W]* pr\. [\w\W]*\)'</span>
            <span class="k">if</span> <span class="s1">' pr. '</span> <span class="ow">in</span> <span class="n">t</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">not_note_pattern</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
                <span class="c1"># short for pronounciation. There's:</span>
                <span class="c1"># also pr. , Taiwain pr. , Japan pr.</span>
                <span class="c1"># However, when the pr. is inside parenthesis, it applies to</span>
                <span class="c1"># the translation which comes before</span>
                <span class="k">continue</span>

            <span class="n">filter_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">for</span> <span class="n">pattern</span> <span class="ow">in</span> <span class="n">filter_out_patterns</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">pattern</span> <span class="ow">in</span> <span class="n">t</span><span class="p">:</span>
                    <span class="n">filter_out</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="n">filter_out</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">t_filtered</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
                    
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_filtered</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dictionary</span><span class="p">[</span><span class="n">hz</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">py</span><span class="p">,</span> <span class="n">t_filtered</span><span class="p">))</span>

<span class="c1">#-----------------------------------------------------------------------</span>
<span class="c1"># Load Weibo word frequencies</span>
<span class="c1">#-----------------------------------------------------------------------</span>
<span class="n">word_freq</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">word_freq_all</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'weibo_wordfreq.release_UTF-8.txt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8-sig'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> 
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
        <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">word_freq_all</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dictionary</span><span class="p">[</span><span class="n">word</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">word_freq</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>

<span class="n">words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">word_freq</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="c1"># Correct the frequency of components (component can not have lower frequency than compound)</span>
<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">word_freq</span><span class="p">[</span><span class="n">w</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">f</span> <span class="o">&lt;</span> <span class="mi">50000</span><span class="p">:</span> <span class="k">continue</span> <span class="c1"># skip uncommon words to speed up</span>
    <span class="n">substrs</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="n">x</span><span class="p">:</span><span class="n">y</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">substr</span> <span class="ow">in</span> <span class="n">substrs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">substr</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span> <span class="k">continue</span>
        <span class="n">subf</span> <span class="o">=</span> <span class="n">word_freq</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">substr</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">subf</span> <span class="o">&lt;</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">word_freq</span><span class="p">[</span><span class="n">substr</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span>
            
<span class="c1"># Calculate word rank, higher for higher frequencies</span>
<span class="n">word_rank</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="n">r</span> <span class="k">for</span> <span class="n">r</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> 
             <span class="nb">enumerate</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">word_freq</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]))}</span>

<span class="c1">#-----------------------------------------------------------------------</span>
<span class="c1"># Load the HSK word lists</span>
<span class="c1">#-----------------------------------------------------------------------</span>
<span class="n">hsk_words_by_lvl</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">hsk_lvl_by_word</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">lvl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">f</span><span class="s1">'hsk/HSK</span><span class="si">{lvl}</span><span class="s1">.txt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8-sig'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="c1"># strip away newlines</span>
            <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">:</span> <span class="k">continue</span> <span class="c1"># some HSK words are not in dict</span>
            <span class="n">words</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">w</span><span class="p">,</span> <span class="n">word_freq</span><span class="p">[</span><span class="n">w</span><span class="p">]))</span>
            <span class="n">hsk_lvl_by_word</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">lvl</span>
    <span class="n">hsk_words_by_lvl</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">words</span>
    
<span class="c1">#-----------------------------------------------------------------------</span>
<span class="c1"># Add components of HSK words as separate HSK words, e.g. ÂêéÈù¢ -&gt; ÂêéÔºå Èù¢</span>
<span class="c1"># This is because the HSK lists are missing most of these components</span>
<span class="c1">#-----------------------------------------------------------------------</span>
<span class="c1"># First, build an index over all HSK words for all their substrings</span>
<span class="n">hsk_word_index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">lvl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">hsk_words_by_lvl</span><span class="p">[</span><span class="n">lvl</span><span class="p">]:</span>
        <span class="n">substrs</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="n">x</span><span class="p">:</span><span class="n">y</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">substr</span> <span class="ow">in</span> <span class="n">substrs</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">curr_lvl</span> <span class="o">=</span> <span class="n">hsk_word_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">substr</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">lvl</span> <span class="o">&lt;</span> <span class="n">curr_lvl</span><span class="p">:</span>
                <span class="n">hsk_word_index</span><span class="p">[</span><span class="n">substr</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">lvl</span><span class="p">)</span>

<span class="c1"># Next, go through all non-HSK words and see if they are a component in an HSK word</span>
<span class="c1"># If so, add them to the corresponding HSK level (if also in dictionary)</span>
<span class="n">component_assignments_per_lvl</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">hsk_lvl_by_word</span><span class="p">:</span>
        <span class="k">continue</span> <span class="c1"># Already is HSK word</span>

    <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">hsk_word_index</span><span class="p">:</span>
        <span class="n">hsk_w</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">lvl</span> <span class="o">=</span> <span class="n">hsk_word_index</span><span class="p">[</span><span class="n">w</span><span class="p">]</span>
        <span class="n">hsk_words_by_lvl</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">w</span><span class="p">,</span> <span class="n">f</span><span class="p">))</span>
        <span class="n">hsk_lvl_by_word</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">lvl</span>
        <span class="n">component_assignments_per_lvl</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">w</span><span class="p">,</span> <span class="n">hsk_w</span><span class="p">))</span>

<span class="c1"># Some debug prints</span>
<span class="k">if</span> <span class="kc">False</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">lvl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>
        <span class="n">words</span> <span class="o">=</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">component_assignments_per_lvl</span><span class="p">[</span><span class="n">lvl</span><span class="p">]])</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'Component HSK </span><span class="si">{lvl}</span><span class="s1"> words:'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">wrap</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="mi">80</span><span class="p">)))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Added for each level: '</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">lvl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'HSK</span><span class="si">{lvl}</span><span class="s1">: {len(component_assignments_per_lvl[lvl])}'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now make a boxplot of the word frequencies of the different HSK levels. As you can see, higher levels tend to have lower frequency words, and also a much smaller range of frequencies. The smaller ranges makes sense, since there are many more ways a word can have high frequency (there is no upper bound), than they can have a low frequency. But ignoring this we can already see that there is significant overlap between the levels.</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (7 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">freqs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">f</span> <span class="k">for</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">hsk_words_by_lvl</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                  <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">words</span><span class="p">])</span>
<span class="n">lvls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">lvl</span> <span class="k">for</span> <span class="n">lvl</span><span class="p">,</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">hsk_words_by_lvl</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                 <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">])</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">lvls</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">freqs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">fliersize</span><span class="o">=</span><span class="mi">0</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.4e7</span><span class="p">),</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">'HSK Level'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'Frequency'</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Worth noting is that these word frequencies are based on a Weibo (Chinese Twitter) dataset. At first I used a corpus based on all kinds of sources like news, novels etc, but Weibo is more colloquial which I think is more representative of the type of language learners are interested in. Ideally, we'd prefer a dataset with text a learner is likely to encounter: course text books, tv-shows and movies, chat</p>
<p>In order to visualize where HSK words end up as a function of frequency, here's a bar chart showing the most common 5000 words with the most frequent to the right. Each colored bar is a word in HSK and white gaps are words not in the HSK. It drives home the point that</p>
<ol>
<li>There is no clear visual separation between levels</li>
<li>HSK really has plenty of gaps in this range</li>
</ol>
</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (13 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Find the k most frequent words and their HSK level</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">common_k_words</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">word_freq</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="o">-</span><span class="n">K</span><span class="p">:]</span>
<span class="n">common_k_words_lvls</span> <span class="o">=</span> <span class="p">[(</span><span class="n">w</span><span class="p">,</span> <span class="n">hsk_lvl_by_word</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">common_k_words</span><span class="p">]</span>

<span class="n">color_map</span> <span class="o">=</span> <span class="p">{</span><span class="kc">None</span><span class="p">:</span> <span class="s1">'white'</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">'blue'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">'orange'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s1">'green'</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="s1">'red'</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="s1">'purple'</span><span class="p">,</span> <span class="mi">6</span><span class="p">:</span> <span class="s1">'brown'</span><span class="p">}</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">color_map</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">lvl</span> <span class="ow">in</span> <span class="n">common_k_words_lvls</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">get_xaxis</span><span class="p">()</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">get_yaxis</span><span class="p">()</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)),</span> <span class="n">width</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's also a good idea to have a look at the distribution of words over frequencies and see if we can learn anything from it.</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (12 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Reverse order to lowest frequency first</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">word_freq_all</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
<span class="n">counts_subrange</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[(</span><span class="n">counts</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">counts</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">)]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span> <span class="c1"># set larger plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">counts_subrange</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Count'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Word Frequency'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">counts_subrange</span><span class="p">),</span> <span class="mi">100</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As it turns out, word frequencies in language corpora tend to follow <a href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipf's law</a>, which is a discrete version of the Pareto distribution on word rank rather than frequency. The second graph, which is a log-log plot, seems to indicate this as well, since the graph of a Pareto distribution should look roughly linear when plotted this way. It's not quite as linear as I'd hoped, but good enough.</p>

</div>
</div>
</div>
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Advanced-modeling">Advanced modeling<a class="anchor-link" href="chinese-placement-test/#Advanced-modeling">¬∂</a>
</h4>
<p>If we want to build a really advanced model, we might want to take word covariances into account. For example, knowing "ÂàÄ - knife" makes knowing "Âèâ - fork" much more likley, because they tend to co-occur and be learned together. This would also include domains of co-occuring words, like "household and child-caring words" which is a domain I know disproportionately well after spending a month at home caring for my son together with my Chinese mother-in-law (who doesn't speak English, I might add).</p>
<p>In the end, I think adding co-occurances would have little ROI for the added complexity, although it might be a topic worth revisiting in the future.</p>

</div>
</div>
</div>
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Making-a-prediction">Making a prediction<a class="anchor-link" href="chinese-placement-test/#Making-a-prediction">¬∂</a>
</h3>
<p>Now that we know our data a bit better we can think about how to predict a user's vocabulary. The idea is to create some kind of interactive procedure to iteratively discover this distribution. This way we can hone in on the user's skill level without asking tons of questions up front.</p>
<p>Still, "knowing" a word is a bit of a loose concept since being able to produce a translation given a Hanzi cue doesn't really show whether you can use it well in a sentence. Or being able to write it, or recognize it in speech etc. There are many ways you could imagine probing the user, but this little proof of concetp I'll simplify the problem to just a binary decision for Hanzi+Pinyin+Translation combos.</p>
<p>First, let's consider a single independent variable, frequency, and see what we can do. Predicting a probability based on a independent variable seems like a perfect job for <em>logistic regression</em>. It works by scaling the independent variable, adding some bias to it and then putting the result through the sigmoid function, producing a value between 0 and 1:</p>
$$\frac{1}{1+e^{-(x^{L}_1 \beta_1 + \ldots + x^{L}_n \beta_n + \beta_c)}}$$<p>Logistic regression finds the best values for the $\beta$ coefficients that minimize the <em>Cross Entropy Loss</em>. Since we are essentially training a separate predictor for each individual user with very few data points, it's a good idea to use a simple model like this, with as few variables as possible in order to avoid overfitting and make sampling easier.</p>
<p>Let's try it by picking some random words from different HSK levels, assigning positive labels to levels 1-3, and negative labels to levels 4-6 and see what it looks like. Due to the underlying Pareto distribution, it's better to use frequency rank rather than the frequency as the independent variable, so that we have a uniform discrete distribution over the words:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (57 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word_rank_list</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">word_rank</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">word_rank_list</span><span class="p">]</span>
<span class="n">ranks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_rank_list</span><span class="p">))</span>
<span class="n">in_hsk</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">w</span> <span class="ow">in</span> <span class="n">hsk_word_index</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">])</span>
<span class="n">hsk_lvls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">hsk_lvl_by_word</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">])</span>

<span class="c1"># -----------------------------------------------------------------------</span>
<span class="c1"># Here are a few different versions of the hsk variable</span>
<span class="c1"># NOTE: out of these options, quadratic has the lowest mean loss and std</span>
<span class="c1"># -----------------------------------------------------------------------</span>
<span class="c1"># Unused:</span>
<span class="c1">#hsk_data = []</span>
<span class="c1"># Quadratic:</span>
<span class="n">hsk_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="mi">7</span> <span class="o">-</span> <span class="n">hsk_lvl_by_word</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">36</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">])]</span>
<span class="c1"># Linear:</span>
<span class="c1">#hsk_data = [np.array([(7 - hsk_lvl_by_word.get(w, 7))/6 for w in words])]</span>
<span class="c1"># Single binary:</span>
<span class="c1">#hsk_data = [np.array([1.0 if w in hsk_lvl_by_word else 0.0 for w in words])]</span>
<span class="c1"># Per level binary:</span>
<span class="c1">#hsk_data = [np.array([1.0 if hsk_lvl_by_word.get(w, None) == lvl else 0.0 for w in words])</span>
<span class="c1">#            for lvl in range(1, 7)]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">ranks</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="o">*</span><span class="n">hsk_data</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
<span class="n">data_hsk_mean</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">in_hsk</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data_hsk_std</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">in_hsk</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">normalized_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">normalized_data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">data_hsk_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">data_hsk_std</span>
<span class="n">normalized_word_rank</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">normalized_data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]))</span>

<span class="k">def</span> <span class="nf">sample_HSK_words_per_lvl</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
    <span class="n">test_words</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Make sure we randomize reproducibly</span>
    <span class="k">for</span> <span class="n">lvl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span>
        <span class="n">test_words</span> <span class="o">=</span> <span class="n">test_words</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">hsk_words_by_lvl</span><span class="p">[</span><span class="n">lvl</span><span class="p">],</span> <span class="n">K</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">test_words</span>

<span class="n">K</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">test_words</span> <span class="o">=</span> <span class="n">sample_HSK_words_per_lvl</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
<span class="n">test_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">normalized_word_rank</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">test_words</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># Set the lower level words as known, rest as unknown</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_words</span><span class="p">))</span>
<span class="n">outcomes</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">test_words</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">plot_logistic_regression</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">y_plot</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_plot</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Probability'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Normalized Frequency rank'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">show</span><span class="p">:</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">'lbfgs'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1e9</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">test_rank</span><span class="p">,</span> <span class="n">outcomes</span><span class="p">)</span>
<span class="n">plot_logistic_regression</span><span class="p">(</span><span class="n">test_rank</span><span class="p">,</span> <span class="n">outcomes</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Active-Learning">Active Learning<a class="anchor-link" href="chinese-placement-test/#Active-Learning">¬∂</a>
</h3>
<p>How much data would we need to make a good prediction, and which words would we pick? Let's pretend that we already have a previous "best guess" logistic regression fit. This best guess could be completely manual, based on the user's rough HSK level, or a fit on a small sample of data. Could we use this estimate to pick good words to inquire about?</p>
<p>My intuition tells me that words close to 0 or 1 probability are not good picks, since we're very sure about them. It would be better to pick words we're uncertain about, around 0.5.</p>
<p>What we want is to find the word which would be the most surprising if we got it wrong, but is also likely to happen. More concretely, we want the <em>surprisal</em> for being wrong, times the probability of being wrong about it.</p>
<p>Suprisal is an actual term in information theory, although most often called "information content". The surprisal/information of an event happening is $I(X) = -\log(P(X))$. This means that if the probability of X happening is 0, we're infinitely surprised if it does actually happen (since $-\log(0)=\infty$). If it's 1, then we're not surprised at all if it happens (since $-\log(1)=0$).</p>
<p>What we're looking for then is the <em>expected</em> surprisal of being wrong for both classes:</p>
$$ \sum_{c \in \{T, F\}} P(W=c)I(W=c) $$<p>This is the same as the <em>entropy</em> for the binary probability distribution for a word. As it turns out, the maximum of this function is X=0.5, following our intuition. It also maximizes the expected loss for the Cross Entropy loss function, which gives further validity to the idea. There are other ways to sample for active learning, e.g. sampling close to the decision boundary, but this one is one of the basic ones and it's what I came up with before knowing what to google for :)</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (10 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">X</span><span class="p">))</span>
<span class="n">E</span> <span class="o">=</span> <span class="o">-</span> <span class="n">y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'y'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'X'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figtext</span><span class="p">(</span><span class="o">.</span><span class="mi">15</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"Red line: the logistic function, blue line: the entropy"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Rather than just picking the highest entropy word, we can instead sample a bunch of words according to the entropy curve above, reflecting our underlying uncertainty.</p>
<p>This way then, we can iteratively sample a bunch of words to test using the best current logistic regression fit, until some stopping criteria.</p>
<p>This begs the question of how to sample words for the first iteration. It's important to get samples in both classes with varied inputs. For symmetry, we can set the coefficients of a logistic regression manually using a rough fluency/HSK level provided by the user. To determine the coefficients to use for the logistic function, we can use the constraints that we want the probability to be 0.5 at a point $x^{L}_{1}, ..., x^{L}_{n}$ that represents the user's level. Then we can solve the intercept $\beta_c$ given our best guess for the influence factors for each input variable $\beta_1, \ldots, \beta_n$:
$$\frac{1}{1+e^{-(x^{L}_1 \beta_1 + \ldots + x^{L}_n \beta_n + \beta_c)}} = 0.5 \implies \beta_c = -(x^{L}_1 \beta_1 + \ldots + x^{L}_n \beta_n)$$</p>
<p>As for setting $x^{L}_{1}, ..., x^{L}_{n}$, for frequency rank I found it best to set it to the upper quartile of the rank within the HSK level. For $\beta$ I found it working best to increase it quadratically with the reverse HSK level, resulting in a narrower distribution for lower levels.</p>
<p>One practical detail for sampling from this distribution is that if done naively, we will get biased sampling due to there being probability mass <em>outside</em> the valid range of values. The result is that when we sample words, we will be biased towards sampling more difficult words. Here we can also see the reason for using rank rather than frequency: if we get even a little bit of probability assigned to the lower frequencies, we'll end up sampling a vast majority of words from there, due to the underlying Pareto distribution.</p>

</div>
</div>
</div>
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="HSK-variable">HSK variable<a class="anchor-link" href="chinese-placement-test/#HSK-variable">¬∂</a>
</h3>
<p>At this point it's time to add in the HSK variable as a predictor. Instead of using a normalized HSK level, it makes more sense to reverse it such that HSK 1 becomes 6 and HSK 6 becomes 1, and "no level" becomes 0. After trying various</p>
<ol>
<li>A binary indicator variable (HSK or not)</li>
<li>Binary indicators for each level</li>
<li>The reversed HSK level</li>
<li>The squared reversed HSK level</li>
</ol>
<p>I found that the squared one worked best, probably related to the doubling of word count for consecutive levels.</p>
<h2 id="Procedure,-Dataset-and-Result">Procedure, Dataset and Result<a class="anchor-link" href="chinese-placement-test/#Procedure,-Dataset-and-Result">¬∂</a>
</h2>
<p>The procedure so far is then:</p>
<ol>
<li>Ask for user's rough fluency level</li>
<li>Set the initial logistic regression coefficients based on said level</li>
<li>Until convergence or maximum number of iterations:<ol>
<li>Sample N words based on word entropy</li>
<li>Collect binary yes/no answers for those words</li>
<li>Perform a logistic regression fit using all sampled and answered words so far</li>
</ol>
</li>
</ol>
<p>How do we make sure this procedure actually works? Well, I have one potential dataset: me. I have 3765 notes in my Anki (an open-source spaced repetition app), which I've exported to a csv. I also add to it the earlier HSK levels which I have completed but not added to Anki, as well as a list of other words which I know, for a total of 5671 words:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (38 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">HANZI_UTF_RANGES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">'</span><span class="se">\u4E00</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\u9FFF</span><span class="s1">'</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">'</span><span class="se">\u3400</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\u4DBF</span><span class="s1">'</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">'</span><span class="se">\uF900</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\uFAFF</span><span class="s1">'</span><span class="p">)</span>
<span class="p">]</span>

<span class="k">def</span> <span class="nf">is_hanzi</span><span class="p">(</span><span class="n">char</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="ow">in</span> <span class="n">HANZI_UTF_RANGES</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">ord</span><span class="p">(</span><span class="n">char</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">start</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">ord</span><span class="p">(</span><span class="n">char</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">end</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="kc">False</span>

<span class="k">def</span> <span class="nf">filter_hanzi</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">char</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">if</span> <span class="n">is_hanzi</span><span class="p">(</span><span class="n">char</span><span class="p">))</span>

<span class="n">anki_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'anki_notes.txt'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">hanzi</span> <span class="o">=</span> <span class="n">filter_hanzi</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
        <span class="c1">#print(line)</span>
        <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="n">hanzi</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">character</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
                <span class="n">anki_words</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">character</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="ow">in</span> <span class="n">jieba</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">hanzi</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'search'</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
                <span class="n">anki_words</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dictionary</span><span class="p">[</span><span class="n">hanzi</span><span class="p">])</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">anki_words</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
                
<span class="c1"># Add words from HSK levels I learned before using Anki</span>
<span class="k">for</span> <span class="n">lvl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">hsk_words_by_lvl</span><span class="p">[</span><span class="n">lvl</span><span class="p">]:</span>
        <span class="n">anki_words</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        
<span class="c1"># Add manually gathered extra words</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'known_words.txt'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">anki_words</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With my vocabulary, I can run as many randomized simulations as I'd like by simply providing answers based on the vocabulary, and then checking the final result in terms of loss over the whole vocabulary and other useful metrics. Below is the code for the whole procedure if you'd like to check it out:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (193 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seed</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">microsecond</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Using seed:'</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="nb">all</span><span class="o">=</span><span class="s1">'raise'</span><span class="p">)</span>

<span class="n">component_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">for</span> <span class="n">lvl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span>
    <span class="n">component_words</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">component_assignments_per_lvl</span><span class="p">[</span><span class="n">lvl</span><span class="p">]))</span>
    
<span class="k">def</span> <span class="nf">prevent_nans</span><span class="p">(</span><span class="n">probs</span><span class="p">):</span>
    <span class="n">probs</span><span class="p">[</span><span class="n">probs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="mf">1e-20</span> <span class="c1"># Prevent NaNs</span>
    <span class="n">probs</span><span class="p">[</span><span class="n">probs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-20</span>

<span class="k">def</span> <span class="nf">lr_prediction_and_sampling_cdf</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">normalized_data</span><span class="p">)</span>
    <span class="n">low_prob</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.01</span>
    <span class="n">prevent_nans</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">expected_information</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">breakpoint</span><span class="p">()</span>
    <span class="n">expected_information</span> <span class="o">=</span> <span class="n">expected_information</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">lr_probs</span> <span class="o">=</span> <span class="n">expected_information</span> <span class="o">/</span> <span class="n">expected_information</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="c1"># Clip the long tail, to compensate for bias (very low probability words)</span>
    <span class="c1">#lr_probs[low_prob] = 0</span>
    <span class="n">lr_cdf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">lr_probs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">plot</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">normalized_data</span><span class="p">[::</span><span class="mi">100</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_probs</span><span class="p">[::</span><span class="mi">100</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">probs</span><span class="p">,</span> <span class="n">lr_cdf</span>
    

<span class="k">def</span> <span class="nf">run_iterative_lr</span><span class="p">(</span><span class="n">include_hsk_lvl</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">plot_lr</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                     <span class="n">term_absdiff_thres</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">term_max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">answer_based_on_anki</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">anki_lvl</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># Ask for HSK level</span>
    <span class="n">user_hsk_lvl</span> <span class="o">=</span> <span class="n">anki_lvl</span>
    <span class="k">while</span> <span class="n">user_hsk_lvl</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"HSK1: Beginner 1"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"HSK2: Beginner 2"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"HSK3: Intermediate 1"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"HSK4: Intermediate 2"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"HSK5: Advanced 1"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"HSK6: Advanced 2"</span><span class="p">)</span>

        <span class="n">answer</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s1">'What is roughly your HSK level, 1-6? '</span><span class="p">)</span>
        <span class="n">fail</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">user_hsk_lvl</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">answer</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">fail</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">user_hsk_lvl</span> <span class="o">&lt;=</span> <span class="mi">6</span><span class="p">):</span>
            <span class="n">fail</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">fail</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Please choose a number between 1-6</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="n">sampled_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">sampled_outcomes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">sampled_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">lr_cdf</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">stats_history</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Set a sampling distribution based on the user's specified HSK level</span>
    <span class="c1"># Found that cubing the reverse of the hsk level is a good initial frequency rank coefficient</span>
    <span class="c1"># Small levels lead to big coefficients, which lead to a narrower sampling distribution</span>
    <span class="c1"># Add a little to the lower levels to make sure low frequency words don't dominate</span>
    <span class="n">initial_sampling_freq_coef</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span> <span class="o">-</span> <span class="n">user_hsk_lvl</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.2</span> <span class="k">if</span> <span class="n">user_hsk_lvl</span> <span class="o">&lt;=</span> <span class="mi">2</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">)</span>
    <span class="n">initial_sampling_intercept</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">normalized_data</span><span class="p">[</span><span class="n">hsk_lvls</span> <span class="o">==</span> <span class="n">user_hsk_lvl</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="o">.</span><span class="mi">75</span><span class="p">)</span> <span class="o">*</span> <span class="n">initial_sampling_freq_coef</span>

    <span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
    <span class="n">lr</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">initial_sampling_freq_coef</span><span class="p">,</span> <span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">normalized_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">lr</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="n">initial_sampling_intercept</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">lr_cdf</span> <span class="o">=</span> <span class="n">lr_prediction_and_sampling_cdf</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">lr_coeffs</span><span class="p">,</span> <span class="n">prev_lr_coeffs</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">def</span> <span class="nf">terminate</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">term_max_iter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">iteration</span> <span class="o">&gt;=</span> <span class="n">term_max_iter</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">term_absdiff_thres</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">prev_lr_coeffs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">sum_absdiff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">lr_coeffs</span> <span class="o">-</span> <span class="n">prev_lr_coeffs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">sum_absdiff</span> <span class="o">&lt;</span> <span class="n">term_absdiff_thres</span>

    
    <span class="k">while</span> <span class="ow">not</span> <span class="n">terminate</span><span class="p">():</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">answer_based_on_anki</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'Iteration {iteration+1}'</span><span class="p">)</span>

        <span class="n">curr_sample</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">curr_sample</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_samples</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">lr_cdf</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">lr_cdf</span><span class="p">)</span> <span class="k">else</span> <span class="n">idx</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">words</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">breakpoint</span><span class="p">()</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="ow">in</span> <span class="n">curr_sample</span> <span class="ow">or</span>
                    <span class="n">w</span> <span class="ow">in</span> <span class="n">sampled_words</span> <span class="ow">or</span>
                    <span class="n">w</span> <span class="ow">in</span> <span class="n">component_words</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="n">curr_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

        <span class="n">outcomes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">sample_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">sample_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">curr_sample</span><span class="p">:</span>
            <span class="n">w</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="n">words</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">normalized_data</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">hsk_lvl</span> <span class="o">=</span> <span class="n">hsk_lvl_by_word</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="c1"># Fix race condition in streams resulting in input coming first</span>
            <span class="k">if</span> <span class="n">answer_based_on_anki</span><span class="p">:</span>
                <span class="n">outcome</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">anki_words</span> <span class="k">else</span> <span class="mf">0.0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'HSK </span><span class="si">{hsk_lvl}</span><span class="s1">: </span><span class="si">{w}</span><span class="s1"> </span><span class="si">{f}</span><span class="s1">'</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">py</span><span class="p">,</span> <span class="n">transls</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">[</span><span class="n">w</span><span class="p">]:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">'</span><span class="si">{py}</span><span class="s1">: {"/".join(transls)}'</span><span class="p">)</span>

                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.05</span><span class="p">)</span>
                <span class="n">answer</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s1">'Do you know it, y/n? '</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">''</span><span class="p">)</span> <span class="c1"># Give space to the next question</span>
                <span class="n">outcome</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">answer</span> <span class="o">==</span> <span class="s1">'y'</span> <span class="k">else</span> <span class="mf">0.0</span>

            <span class="n">sampled_words</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
            <span class="n">outcomes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">outcome</span><span class="p">)</span>

        <span class="n">sampled_indices</span> <span class="o">=</span> <span class="n">sampled_indices</span> <span class="o">+</span> <span class="n">curr_sample</span>
        <span class="n">sampled_outcomes</span> <span class="o">=</span> <span class="n">sampled_outcomes</span> <span class="o">+</span> <span class="n">outcomes</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sampled_outcomes</span><span class="p">)))</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># Need data from both true/false classes before doing regression</span>
            <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">continue</span>

        <span class="c1"># NOTE: have to set a higher C in order to reduce regularization</span>
        <span class="c1"># see https://stackoverflow.com/a/52064154</span>
        <span class="c1"># By default C=1.0 which produces very high regularization</span>
        <span class="c1"># But we still need some regularization, especially when an HSK1-3 student</span>
        <span class="c1"># don't know any words outside HSK, this will make the estimate for rank coefficient</span>
        <span class="c1"># too extreme</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">'lbfgs'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1e2</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">normalized_data</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sampled_indices</span><span class="p">)]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sampled_outcomes</span><span class="p">)</span>
        <span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        
        <span class="n">prev_lr_coeffs</span><span class="p">,</span> <span class="n">lr_coeffs</span> <span class="o">=</span> <span class="n">lr_coeffs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">lr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
        <span class="n">probs</span><span class="p">,</span> <span class="n">lr_cdf</span> <span class="o">=</span> <span class="n">lr_prediction_and_sampling_cdf</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Evaluate Cross Entropy Loss on words in Anki</span>
        <span class="n">anki_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">w</span> <span class="ow">in</span> <span class="n">anki_words</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">])</span>
        <span class="n">anki_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="n">anki_mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">not_anki_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="o">~</span><span class="n">anki_mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">anki_loss</span> <span class="o">+</span> <span class="n">not_anki_loss</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'anki_loss'</span><span class="p">:</span> <span class="n">anki_loss</span><span class="p">,</span> <span class="s1">'not_anki_loss'</span><span class="p">:</span> <span class="n">not_anki_loss</span><span class="p">,</span> <span class="s1">'loss'</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
                 <span class="s1">'outcomes'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">outcomes</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">outcomes</span><span class="p">),</span> <span class="s1">'coeffs'</span><span class="p">:</span> <span class="n">lr_coeffs</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">hsk</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]:</span>
            <span class="n">hsk_mask</span> <span class="o">=</span> <span class="n">in_hsk</span> <span class="k">if</span> <span class="n">hsk</span> <span class="k">else</span> <span class="o">~</span><span class="n">in_hsk</span>
            <span class="n">pos_outcomes</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
            <span class="n">neg_outcomes</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span>
            <span class="n">false_negatives</span> <span class="o">=</span> <span class="n">anki_mask</span> <span class="o">&amp;</span> <span class="n">hsk_mask</span> <span class="o">&amp;</span> <span class="n">neg_outcomes</span>
            <span class="n">false_positives</span> <span class="o">=</span> <span class="o">~</span><span class="n">anki_mask</span> <span class="o">&amp;</span> <span class="n">hsk_mask</span> <span class="o">&amp;</span> <span class="n">pos_outcomes</span>
            <span class="n">true_negatives</span> <span class="o">=</span> <span class="o">~</span><span class="n">anki_mask</span> <span class="o">&amp;</span> <span class="n">hsk_mask</span> <span class="o">&amp;</span> <span class="n">neg_outcomes</span>
            <span class="n">true_positives</span> <span class="o">=</span> <span class="n">anki_mask</span> <span class="o">&amp;</span> <span class="n">hsk_mask</span> <span class="o">&amp;</span> <span class="n">pos_outcomes</span>
            <span class="n">prefix</span> <span class="o">=</span> <span class="s2">"hsk_"</span> <span class="k">if</span> <span class="n">hsk</span> <span class="k">else</span> <span class="s2">"not_hsk_"</span>
            <span class="n">stats</span><span class="p">[</span><span class="n">prefix</span><span class="o">+</span><span class="s1">'FN'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">false_negatives</span><span class="p">)</span>
            <span class="n">stats</span><span class="p">[</span><span class="n">prefix</span><span class="o">+</span><span class="s1">'FP'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">false_positives</span><span class="p">)</span>
            <span class="n">stats</span><span class="p">[</span><span class="n">prefix</span><span class="o">+</span><span class="s1">'TN'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">true_negatives</span><span class="p">)</span>
            <span class="n">stats</span><span class="p">[</span><span class="n">prefix</span><span class="o">+</span><span class="s1">'TP'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span>

        <span class="n">stats_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stats</span><span class="p">)</span>
        <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">stats_history</span>

<span class="n">NUM_ITER</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">NUM_RUNS</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1">#run_iterative_lr(include_hsk_lvl=True, plot_lr=False, term_max_iter=NUM_ITER,</span>
<span class="c1">#                 answer_based_on_anki=False, anki_lvl=2)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">iteration</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">final_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_RUNS</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Run '</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">stats_history</span> <span class="o">=</span> <span class="n">run_iterative_lr</span><span class="p">(</span><span class="n">include_hsk_lvl</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">plot_lr</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">term_max_iter</span><span class="o">=</span><span class="n">NUM_ITER</span><span class="p">,</span>
                                     <span class="n">answer_based_on_anki</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">anki_lvl</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">stats</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">stats_history</span><span class="p">):</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stats</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">])</span>
        <span class="n">outcomes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stats</span><span class="p">[</span><span class="s1">'outcomes'</span><span class="p">])</span>
        <span class="n">iteration</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">final_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stats_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">'loss'</span><span class="p">])</span>
<span class="n">final_losses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">final_losses</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Mean final loss:'</span><span class="p">,</span> <span class="n">final_losses</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="s1">' std'</span><span class="p">,</span> <span class="n">final_losses</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Done'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are two key graphs:</p>
<ol>
<li>The average loss over time for 100 randomized simulation runs. We naturally expect this loss to go down over time.</li>
<li>The percent of words that are answered correctly each iteration. We expect this to be around 0.5 if the fit is good. Due to previously mentioned sampling bias, the actual average is lower than that. After trying to correct for this, it's clear that there is still some difference of about 10% that I cannot account for.</li>
</ol>
</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (7 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">iteration</span><span class="p">),</span> <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">loss</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">'Iteration'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'Loss'</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">f</span><span class="s1">'Loss over </span><span class="si">{NUM_RUNS}</span><span class="s1"> runs'</span><span class="p">);</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">iteration</span><span class="p">),</span> <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">outcomes</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">'Iteration'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'% known'</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">f</span><span class="s1">'% Known words over </span><span class="si">{NUM_RUNS}</span><span class="s1"> runs'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="False-Positives-and-False-Negatives">False Positives and False Negatives<a class="anchor-link" href="chinese-placement-test/#False-Positives-and-False-Negatives">¬∂</a>
</h3>
<p>A useful statistic for figuring out how well this system is actually doing is false positives and false negatives. We can use the predicted probabilities and threshold on &gt; 0.5 to get a binary classification for each word. Here you can see the outcomes for the words in my dataset:</p>

</div>
</div>
</div>
  
  
  
    
      
        
        

        
          
          
          <div class="toggleoff">
              <div style="display: flex; justify-content: flex-start">
                <a class="showbutton" onclick="toggle(this)" style="cursor: pointer">show code (26 lines)</a>
                <a class="hidebutton" onclick="toggle(this)" style="cursor: pointer">hide code</a>
              </div>
            <div class="cellwrapper">
              <div class="input">

        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="k">import</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">display</span>
<span class="kn">import</span> <span class="nn">tabulate</span>

<span class="n">h</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">stats_history</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">precision</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">recall</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">hsk</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]:</span>
    <span class="n">pre</span> <span class="o">=</span> <span class="s1">'hsk_'</span> <span class="k">if</span> <span class="n">hsk</span> <span class="k">else</span> <span class="s1">'not_hsk_'</span>
    <span class="n">FN</span> <span class="o">=</span> <span class="n">h</span><span class="p">[</span><span class="n">pre</span><span class="o">+</span><span class="s1">'FN'</span><span class="p">]</span>
    <span class="n">FP</span> <span class="o">=</span> <span class="n">h</span><span class="p">[</span><span class="n">pre</span><span class="o">+</span><span class="s1">'FP'</span><span class="p">]</span>
    <span class="n">TP</span> <span class="o">=</span> <span class="n">h</span><span class="p">[</span><span class="n">pre</span><span class="o">+</span><span class="s1">'TP'</span><span class="p">]</span>
    <span class="n">TN</span> <span class="o">=</span> <span class="n">h</span><span class="p">[</span><span class="n">pre</span><span class="o">+</span><span class="s1">'TN'</span><span class="p">]</span>
    <span class="n">table</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">"HSK"</span> <span class="k">if</span> <span class="n">hsk</span> <span class="k">else</span> <span class="s2">"Non-HSK"</span><span class="p">,</span> <span class="s2">"Negatives"</span><span class="p">,</span><span class="s2">"Positives"</span><span class="p">],</span>
             <span class="p">[</span><span class="s2">"False"</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">FP</span><span class="p">],</span>
             <span class="p">[</span><span class="s2">"True"</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">TP</span><span class="p">]]</span>
    <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">tabulate</span><span class="o">.</span><span class="n">tabulate</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"firstrow"</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s1">'html'</span><span class="p">)))</span>
    <span class="n">accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">TP</span><span class="o">+</span><span class="n">TN</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">TN</span><span class="o">+</span><span class="n">FP</span><span class="o">+</span><span class="n">FN</span><span class="p">))</span>
    <span class="n">precision</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s1">'nan'</span><span class="p">)</span> <span class="k">if</span> <span class="n">TP</span><span class="o">+</span><span class="n">FP</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">TP</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FP</span><span class="p">))</span>
    <span class="n">recall</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TP</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FN</span><span class="p">))</span>
    
<span class="n">table</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">"HSK"</span><span class="p">,</span><span class="s2">"Non-HSK"</span><span class="p">],</span>
         <span class="p">[</span><span class="s2">"Accuracy"</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">accuracy</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
         <span class="p">[</span><span class="s2">"Precision"</span><span class="p">,</span> <span class="n">precision</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">precision</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
         <span class="p">[</span><span class="s2">"Recall"</span><span class="p">,</span> <span class="n">recall</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">recall</span><span class="p">[</span><span class="mi">1</span><span class="p">]]]</span>
<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">tabulate</span><span class="o">.</span><span class="n">tabulate</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"firstrow"</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s1">'html'</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

            </div>
          </div>
        
    

    
      
        
        
        
          
<div class="output_wrapper">
<div class="output">

        
<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<table>
<thead><tr>
<th>HSK  </th>
<th style="text-align: right;">  Negatives</th>
<th style="text-align: right;">  Positives</th>
</tr></thead>
<tbody>
<tr>
<td>False</td>
<td style="text-align: right;">        828</td>
<td style="text-align: right;">        436</td>
</tr>
<tr>
<td>True </td>
<td style="text-align: right;">       2924</td>
<td style="text-align: right;">       2813</td>
</tr>
</tbody>
</table>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<table>
<thead><tr>
<th>Non-HSK  </th>
<th style="text-align: right;">  Negatives</th>
<th style="text-align: right;">  Positives</th>
</tr></thead>
<tbody>
<tr>
<td>False    </td>
<td style="text-align: right;">       1637</td>
<td style="text-align: right;">         40</td>
</tr>
<tr>
<td>True     </td>
<td style="text-align: right;">      46454</td>
<td style="text-align: right;">        169</td>
</tr>
</tbody>
</table>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<table>
<thead><tr>
<th>         </th>
<th style="text-align: right;">     HSK</th>
<th style="text-align: right;">  Non-HSK</th>
</tr></thead>
<tbody>
<tr>
<td>Accuracy </td>
<td style="text-align: right;">0.819454</td>
<td style="text-align: right;"> 0.96528 </td>
</tr>
<tr>
<td>Precision</td>
<td style="text-align: right;">0.865805</td>
<td style="text-align: right;"> 0.808612</td>
</tr>
<tr>
<td>Recall   </td>
<td style="text-align: right;">0.77259 </td>
<td style="text-align: right;"> 0.093577</td>
</tr>
</tbody>
</table>
</div>

</div>

</div>
</div>

        
    
  
  
  
    
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we can see for the Non-HSK table, <em>most</em> non-HSK words in my vocabulary are misclassified as "don't know" (low recall) even though precision is fairly high. This shows how tough it is to predict vocabulary outside the HSK using only frequency.</p>
<h2 id="Conclusion">Conclusion<a class="anchor-link" href="chinese-placement-test/#Conclusion">¬∂</a>
</h2>
<p>Hopefully I've show that we can build a placement test that would shorted the on-boarding time in learning apps. Whether it generalizes well outside my own vocabulary is left to be seen. If you're reading this and is willing to donate your Anki notes, I'd happily accept them so that I can run more experiements!</p>
<p>While I've specifically applied it to Chinese, the general structure could be applied to any topic where there is some indication of frequency, difficulty or general order of study. For Chinese, we could imagine splitting reading, writing, listening and (speech) synthesis into different placement tests since learners often place different emphasis on them.</p>
<p>If you have any ideas or comments, please use the comment section below.</p>

</div>
</div>
</div>
</div>
    </div>
    </article>
</div>



        
       <script>var disqus_shortname="martindbp";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script><footer id="footer"><p>Contents ¬© 2019         <a href="mailto:me@martindbp.com">Martin Pettersson</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         </p>
            
        </footer>
</div>
    </div>
    <label for="sidebar-checkbox" class="sidebar-toggle"></label>
    
    
    
            <script src="../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script type="text/javascript">
      var toggle = function(id) {
        toggleDiv = id.parentNode.parentNode
        if (toggleDiv.classList.contains('toggleon')) {
          toggleDiv.classList.remove('toggleon');
          toggleDiv.classList.add('toggleoff');
        }
        else {
          toggleDiv.classList.remove('toggleoff');
          toggleDiv.classList.add('toggleon');
        }
      };
    </script>
</body>
</html>
